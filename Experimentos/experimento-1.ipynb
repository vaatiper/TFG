{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall tensorflow-datasets tensorflow-metadata -y\n",
        "!pip install tensorflow==2.11\n",
        "!pip install sciann"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSd_fhcJKJGG",
        "outputId": "7a17276f-5858-4398-a990-332c7d5e1bde"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping tensorflow-datasets as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping tensorflow-metadata as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: tensorflow==2.11 in /usr/local/lib/python3.10/dist-packages (2.11.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (24.3.25)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (1.64.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (3.9.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (2.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (18.1.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (24.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (3.19.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (2.11.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (2.11.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (0.37.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.11) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow==2.11) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11) (3.2.2)\n",
            "Requirement already satisfied: sciann in /usr/local/lib/python3.10/dist-packages (0.7.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sciann) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sciann) (1.11.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sciann) (1.16.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from sciann) (6.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from sciann) (3.9.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sciann) (1.2.2)\n",
            "Requirement already satisfied: pybtex in /usr/local/lib/python3.10/dist-packages (from sciann) (0.24.0)\n",
            "Requirement already satisfied: latexcodec>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from pybtex->sciann) (3.0.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sciann) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sciann) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1. Ajuste de la curva $y = sin(x)$ en el intervalo $[0,2\\pi]$."
      ],
      "metadata": {
        "id": "uLxezGuvbd47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sciann import Variable, Functional, SciModel\n",
        "from sciann.constraints import Data\n",
        "import sciann as sn\n",
        "import time\n",
        "\n",
        "\n",
        "# Generación de datos sintéticos.\n",
        "x_true = np.linspace(0, np.pi*2, 10000)\n",
        "y_true = np.sin(x_true)\n",
        "dy_true = np.cos(x_true)\n",
        "\n",
        "# Definimos la estructura de la función que queremos aprender.\n",
        "x = Variable('x')\n",
        "xf = Functional('xf', x)\n",
        "xf.set_trainable(False)\n",
        "\n",
        "\n",
        "y = Functional('y', x, [10, 10, 10], activation=['tanh', 'g-cos', 'l-sin'])\n",
        "dy_dx = sn.diff(y, x)\n",
        "\n",
        "\n",
        "\n",
        "# Imponemos restricciones al modelo.\n",
        "c1 = Data(y)\n",
        "\n",
        "# Definimos el modelo.\n",
        "model = SciModel(x, [y, dy_dx], optimizer='adam')\n",
        "model.summary()\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Entrenamiento.\n",
        "model.train(x_true,\n",
        "            [y_true, dy_true],\n",
        "            epochs=200,\n",
        "            learning_rate={\"scheduler\": \"ExponentialDecay\",\n",
        "                           \"initial_learning_rate\": 1e-3,\n",
        "                           \"final_learning_rate\": 1e-5,\n",
        "                           \"decay_epochs\": 10,\n",
        "                           \"verify\": False},\n",
        "            batch_size=32,\n",
        "            # adaptive_weights={'method': \"SASW\", \"eta\": 0.1, \"d_mask_func\": lambda x: np.exp(x)},\n",
        "            adaptive_weights={'method': \"CLW\", 'initial_weights': [0.1, 1.], 'final_weights': [2., 3.], 'curriculum_epochs': 20, \"delay_epochs\": 10},\n",
        "            save_weights={'path': 'test', 'freq': 100}\n",
        "            )\n",
        "\n",
        "print(f\"Training finished in {time.time()-start_time}s. \")\n",
        "\n",
        "# Predicción\n",
        "y_pred = y.eval(model, x_true)\n",
        "\n",
        "# Mostramos los resultados\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(x_true, y_true, '-k', x_true, y_pred, '--r')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xdZqfFYYOQYW",
        "outputId": "21f26e6e-598f-459c-c47c-2f35229df7a3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Call `model.compile()` after using set_trainable.\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " x (InputLayer)              [(None, 1)]               0         \n",
            "                                                                 \n",
            " D10b_4 (Dense)              (None, 10)                20        \n",
            "                                                                 \n",
            " sci_rowdy_activation_layer_  (None, 10)               14        \n",
            " 3 (SciRowdyActivationLayer)                                     \n",
            "                                                                 \n",
            " D10b_5 (Dense)              (None, 10)                110       \n",
            "                                                                 \n",
            " sci_rowdy_activation_layer_  (None, 10)               14        \n",
            " 4 (SciRowdyActivationLayer)                                     \n",
            "                                                                 \n",
            " D10b_6 (Dense)              (None, 10)                110       \n",
            "                                                                 \n",
            " sci_rowdy_activation_layer_  (None, 10)               14        \n",
            " 5 (SciRowdyActivationLayer)                                     \n",
            "                                                                 \n",
            " y (Field)                   (None, 1)                 11        \n",
            "                                                                 \n",
            " Grad__2 (Lambda)            (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 293\n",
            "Trainable params: 293\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Total samples: 10000 \n",
            "Batch size: 32 \n",
            "Total batches: 313 \n",
            "\n",
            "\n",
            "+ adaptive_weights is set to:  [0.1, 1.0]\n",
            "Epoch 1/200\n",
            "313/313 [==============================] - 4s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.1364 - y_loss: 0.1304 - Grad__2_loss: 0.1234 - lr: 0.0010 - time: 3.6644 - loss_weight_0: 0.1000 - loss_weight_1: 1.0000\n",
            "Epoch 2/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.0724e-05 - y_loss: 2.6580e-06 - Grad__2_loss: 2.0458e-05 - lr: 6.3096e-04 - time: 1.3837 - loss_weight_0: 0.1000 - loss_weight_1: 1.0000\n",
            "Epoch 3/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.3526e-05 - y_loss: 1.2700e-06 - Grad__2_loss: 1.3399e-05 - lr: 3.9811e-04 - time: 1.4225 - loss_weight_0: 0.1000 - loss_weight_1: 1.0000\n",
            "Epoch 4/200\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.0405e-05 - y_loss: 9.6479e-07 - Grad__2_loss: 1.0308e-05 - lr: 2.5119e-04 - time: 1.8074 - loss_weight_0: 0.1000 - loss_weight_1: 1.0000\n",
            "Epoch 5/200\n",
            "313/313 [==============================] - 2s 7ms/step - batch: 156.0000 - size: 31.9489 - loss: 8.6185e-06 - y_loss: 7.5233e-07 - Grad__2_loss: 8.5432e-06 - lr: 1.5849e-04 - time: 2.2474 - loss_weight_0: 0.1000 - loss_weight_1: 1.0000\n",
            "Epoch 6/200\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 7.5141e-06 - y_loss: 5.8693e-07 - Grad__2_loss: 7.4554e-06 - lr: 1.0000e-04 - time: 1.5087 - loss_weight_0: 0.1000 - loss_weight_1: 1.0000\n",
            "Epoch 7/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 6.7810e-06 - y_loss: 5.0714e-07 - Grad__2_loss: 6.7303e-06 - lr: 6.3096e-05 - time: 1.4513 - loss_weight_0: 0.1000 - loss_weight_1: 1.0000\n",
            "Epoch 8/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 6.3081e-06 - y_loss: 4.5464e-07 - Grad__2_loss: 6.2626e-06 - lr: 3.9811e-05 - time: 1.3026 - loss_weight_0: 0.1000 - loss_weight_1: 1.0000\n",
            "Epoch 9/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 5.9732e-06 - y_loss: 3.9933e-07 - Grad__2_loss: 5.9333e-06 - lr: 2.5119e-05 - time: 1.3942 - loss_weight_0: 0.1000 - loss_weight_1: 1.0000\n",
            "Epoch 10/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 5.7587e-06 - y_loss: 3.7485e-07 - Grad__2_loss: 5.7212e-06 - lr: 1.5849e-05 - time: 1.3798 - loss_weight_0: 0.1000 - loss_weight_1: 1.0000\n",
            "\n",
            "+ adaptive_weights at epoch 11: [0.1, 1.0]\n",
            "Epoch 11/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 5.5906e-06 - y_loss: 3.6839e-07 - Grad__2_loss: 5.5537e-06 - lr: 1.0000e-05 - time: 1.2906 - loss_weight_0: 0.1000 - loss_weight_1: 1.0000\n",
            "\n",
            "+ adaptive_weights at epoch 12: [0.195, 1.1]\n",
            "Epoch 12/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 6.0181e-06 - y_loss: 3.5698e-07 - Grad__2_loss: 5.4077e-06 - lr: 1.0000e-05 - time: 1.3187 - loss_weight_0: 0.1950 - loss_weight_1: 1.1000\n",
            "\n",
            "+ adaptive_weights at epoch 13: [0.29000000000000004, 1.2]\n",
            "Epoch 13/200\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 6.3818e-06 - y_loss: 3.4949e-07 - Grad__2_loss: 5.2337e-06 - lr: 1.0000e-05 - time: 1.6454 - loss_weight_0: 0.2900 - loss_weight_1: 1.2000\n",
            "\n",
            "+ adaptive_weights at epoch 14: [0.385, 1.3]\n",
            "Epoch 14/200\n",
            "313/313 [==============================] - 2s 7ms/step - batch: 156.0000 - size: 31.9489 - loss: 6.6703e-06 - y_loss: 3.3304e-07 - Grad__2_loss: 5.0324e-06 - lr: 1.0000e-05 - time: 2.1559 - loss_weight_0: 0.3850 - loss_weight_1: 1.3000\n",
            "\n",
            "+ adaptive_weights at epoch 15: [0.48, 1.4]\n",
            "Epoch 15/200\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 6.8424e-06 - y_loss: 3.1323e-07 - Grad__2_loss: 4.7801e-06 - lr: 1.0000e-05 - time: 1.6772 - loss_weight_0: 0.4800 - loss_weight_1: 1.4000\n",
            "\n",
            "+ adaptive_weights at epoch 16: [0.575, 1.5]\n",
            "Epoch 16/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 6.9126e-06 - y_loss: 3.0203e-07 - Grad__2_loss: 4.4926e-06 - lr: 1.0000e-05 - time: 1.3334 - loss_weight_0: 0.5750 - loss_weight_1: 1.5000\n",
            "\n",
            "+ adaptive_weights at epoch 17: [0.67, 1.6]\n",
            "Epoch 17/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 6.8569e-06 - y_loss: 2.8183e-07 - Grad__2_loss: 4.1676e-06 - lr: 1.0000e-05 - time: 1.2862 - loss_weight_0: 0.6700 - loss_weight_1: 1.6000\n",
            "\n",
            "+ adaptive_weights at epoch 18: [0.765, 1.7000000000000002]\n",
            "Epoch 18/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 6.7166e-06 - y_loss: 2.5993e-07 - Grad__2_loss: 3.8340e-06 - lr: 1.0000e-05 - time: 1.3031 - loss_weight_0: 0.7650 - loss_weight_1: 1.7000\n",
            "\n",
            "+ adaptive_weights at epoch 19: [0.86, 1.8]\n",
            "Epoch 19/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 6.4677e-06 - y_loss: 2.3285e-07 - Grad__2_loss: 3.4819e-06 - lr: 1.0000e-05 - time: 1.2868 - loss_weight_0: 0.8600 - loss_weight_1: 1.8000\n",
            "\n",
            "+ adaptive_weights at epoch 20: [0.955, 1.9]\n",
            "Epoch 20/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 6.1539e-06 - y_loss: 2.2378e-07 - Grad__2_loss: 3.1264e-06 - lr: 1.0000e-05 - time: 1.3436 - loss_weight_0: 0.9550 - loss_weight_1: 1.9000\n",
            "\n",
            "+ adaptive_weights at epoch 21: [1.05, 2.0]\n",
            "Epoch 21/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 5.7162e-06 - y_loss: 1.8794e-07 - Grad__2_loss: 2.7594e-06 - lr: 1.0000e-05 - time: 1.4275 - loss_weight_0: 1.0500 - loss_weight_1: 2.0000\n",
            "\n",
            "+ adaptive_weights at epoch 22: [1.145, 2.1]\n",
            "Epoch 22/200\n",
            "313/313 [==============================] - 1s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 5.2596e-06 - y_loss: 1.6875e-07 - Grad__2_loss: 2.4126e-06 - lr: 1.0000e-05 - time: 1.4998 - loss_weight_0: 1.1450 - loss_weight_1: 2.1000\n",
            "\n",
            "+ adaptive_weights at epoch 23: [1.2400000000000002, 2.2]\n",
            "Epoch 23/200\n",
            "313/313 [==============================] - 2s 7ms/step - batch: 156.0000 - size: 31.9489 - loss: 4.7943e-06 - y_loss: 1.4663e-07 - Grad__2_loss: 2.0966e-06 - lr: 1.0000e-05 - time: 2.0999 - loss_weight_0: 1.2400 - loss_weight_1: 2.2000\n",
            "\n",
            "+ adaptive_weights at epoch 24: [1.3350000000000002, 2.3]\n",
            "Epoch 24/200\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 4.3160e-06 - y_loss: 1.2701e-07 - Grad__2_loss: 1.8028e-06 - lr: 1.0000e-05 - time: 1.8001 - loss_weight_0: 1.3350 - loss_weight_1: 2.3000\n",
            "\n",
            "+ adaptive_weights at epoch 25: [1.4300000000000002, 2.4000000000000004]\n",
            "Epoch 25/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 3.8317e-06 - y_loss: 1.0713e-07 - Grad__2_loss: 1.5327e-06 - lr: 1.0000e-05 - time: 1.4002 - loss_weight_0: 1.4300 - loss_weight_1: 2.4000\n",
            "\n",
            "+ adaptive_weights at epoch 26: [1.5250000000000001, 2.5]\n",
            "Epoch 26/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 3.3916e-06 - y_loss: 9.3402e-08 - Grad__2_loss: 1.2996e-06 - lr: 1.0000e-05 - time: 1.3829 - loss_weight_0: 1.5250 - loss_weight_1: 2.5000\n",
            "\n",
            "+ adaptive_weights at epoch 27: [1.62, 2.6]\n",
            "Epoch 27/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 3.0013e-06 - y_loss: 8.0760e-08 - Grad__2_loss: 1.1040e-06 - lr: 1.0000e-05 - time: 1.3958 - loss_weight_0: 1.6200 - loss_weight_1: 2.6000\n",
            "\n",
            "+ adaptive_weights at epoch 28: [1.715, 2.7]\n",
            "Epoch 28/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.6444e-06 - y_loss: 7.0027e-08 - Grad__2_loss: 9.3492e-07 - lr: 1.0000e-05 - time: 1.4027 - loss_weight_0: 1.7150 - loss_weight_1: 2.7000\n",
            "\n",
            "+ adaptive_weights at epoch 29: [1.81, 2.8]\n",
            "Epoch 29/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.3352e-06 - y_loss: 6.1656e-08 - Grad__2_loss: 7.9415e-07 - lr: 1.0000e-05 - time: 1.3835 - loss_weight_0: 1.8100 - loss_weight_1: 2.8000\n",
            "\n",
            "+ adaptive_weights at epoch 30: [1.905, 2.9000000000000004]\n",
            "Epoch 30/200\n",
            "313/313 [==============================] - 1s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.0590e-06 - y_loss: 4.8467e-08 - Grad__2_loss: 6.7815e-07 - lr: 1.0000e-05 - time: 1.4955 - loss_weight_0: 1.9050 - loss_weight_1: 2.9000\n",
            "\n",
            "+ adaptive_weights at epoch 31: [2.0, 3.0]\n",
            "Epoch 31/200\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.8396e-06 - y_loss: 4.6184e-08 - Grad__2_loss: 5.8243e-07 - lr: 1.0000e-05 - time: 1.8161 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 32: [2.0, 3.0]\n",
            "Epoch 32/200\n",
            "313/313 [==============================] - 2s 7ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.6059e-06 - y_loss: 4.0384e-08 - Grad__2_loss: 5.0838e-07 - lr: 1.0000e-05 - time: 2.2552 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 33: [2.0, 3.0]\n",
            "Epoch 33/200\n",
            "313/313 [==============================] - 1s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.4069e-06 - y_loss: 3.4827e-08 - Grad__2_loss: 4.4575e-07 - lr: 1.0000e-05 - time: 1.4498 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 34: [2.0, 3.0]\n",
            "Epoch 34/200\n",
            "313/313 [==============================] - 1s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.2566e-06 - y_loss: 3.0965e-08 - Grad__2_loss: 3.9823e-07 - lr: 1.0000e-05 - time: 1.4799 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 35: [2.0, 3.0]\n",
            "Epoch 35/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.1336e-06 - y_loss: 2.8328e-08 - Grad__2_loss: 3.5897e-07 - lr: 1.0000e-05 - time: 1.3505 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 36: [2.0, 3.0]\n",
            "Epoch 36/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.0284e-06 - y_loss: 2.6468e-08 - Grad__2_loss: 3.2517e-07 - lr: 1.0000e-05 - time: 1.4045 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 37: [2.0, 3.0]\n",
            "Epoch 37/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 9.4088e-07 - y_loss: 2.4192e-08 - Grad__2_loss: 2.9750e-07 - lr: 1.0000e-05 - time: 1.3413 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 38: [2.0, 3.0]\n",
            "Epoch 38/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 8.7023e-07 - y_loss: 2.4444e-08 - Grad__2_loss: 2.7378e-07 - lr: 1.0000e-05 - time: 1.2935 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 39: [2.0, 3.0]\n",
            "Epoch 39/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 8.1122e-07 - y_loss: 2.3017e-08 - Grad__2_loss: 2.5506e-07 - lr: 1.0000e-05 - time: 1.3458 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 40: [2.0, 3.0]\n",
            "Epoch 40/200\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 7.5127e-07 - y_loss: 1.9358e-08 - Grad__2_loss: 2.3752e-07 - lr: 1.0000e-05 - time: 1.7664 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 41: [2.0, 3.0]\n",
            "Epoch 41/200\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 7.0583e-07 - y_loss: 1.9551e-08 - Grad__2_loss: 2.2224e-07 - lr: 1.0000e-05 - time: 1.9831 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 42: [2.0, 3.0]\n",
            "Epoch 42/200\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 6.5790e-07 - y_loss: 1.6989e-08 - Grad__2_loss: 2.0797e-07 - lr: 1.0000e-05 - time: 1.5110 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 43: [2.0, 3.0]\n",
            "Epoch 43/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 6.1990e-07 - y_loss: 1.6245e-08 - Grad__2_loss: 1.9580e-07 - lr: 1.0000e-05 - time: 1.2600 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 44: [2.0, 3.0]\n",
            "Epoch 44/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 5.9740e-07 - y_loss: 1.7384e-08 - Grad__2_loss: 1.8754e-07 - lr: 1.0000e-05 - time: 1.3341 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 45: [2.0, 3.0]\n",
            "Epoch 45/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 5.6478e-07 - y_loss: 1.5289e-08 - Grad__2_loss: 1.7807e-07 - lr: 1.0000e-05 - time: 1.3244 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 46: [2.0, 3.0]\n",
            "Epoch 46/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 5.4953e-07 - y_loss: 1.6796e-08 - Grad__2_loss: 1.7198e-07 - lr: 1.0000e-05 - time: 1.2956 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 47: [2.0, 3.0]\n",
            "Epoch 47/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 5.1978e-07 - y_loss: 1.3307e-08 - Grad__2_loss: 1.6439e-07 - lr: 1.0000e-05 - time: 1.3491 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 48: [2.0, 3.0]\n",
            "Epoch 48/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 5.1237e-07 - y_loss: 1.6333e-08 - Grad__2_loss: 1.5990e-07 - lr: 1.0000e-05 - time: 1.2634 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 49: [2.0, 3.0]\n",
            "Epoch 49/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 4.9336e-07 - y_loss: 1.4645e-08 - Grad__2_loss: 1.5469e-07 - lr: 1.0000e-05 - time: 1.3890 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 50: [2.0, 3.0]\n",
            "Epoch 50/200\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 4.8192e-07 - y_loss: 1.5277e-08 - Grad__2_loss: 1.5045e-07 - lr: 1.0000e-05 - time: 2.0580 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 51: [2.0, 3.0]\n",
            "Epoch 51/200\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 4.5864e-07 - y_loss: 1.0801e-08 - Grad__2_loss: 1.4568e-07 - lr: 1.0000e-05 - time: 1.9415 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 52: [2.0, 3.0]\n",
            "Epoch 52/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 4.5291e-07 - y_loss: 1.2994e-08 - Grad__2_loss: 1.4231e-07 - lr: 1.0000e-05 - time: 1.2885 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 53: [2.0, 3.0]\n",
            "Epoch 53/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 4.4396e-07 - y_loss: 1.2896e-08 - Grad__2_loss: 1.3939e-07 - lr: 1.0000e-05 - time: 1.3096 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 54: [2.0, 3.0]\n",
            "Epoch 54/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 4.3840e-07 - y_loss: 1.3361e-08 - Grad__2_loss: 1.3723e-07 - lr: 1.0000e-05 - time: 1.3068 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 55: [2.0, 3.0]\n",
            "Epoch 55/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 4.2802e-07 - y_loss: 1.2768e-08 - Grad__2_loss: 1.3416e-07 - lr: 1.0000e-05 - time: 1.2897 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 56: [2.0, 3.0]\n",
            "Epoch 56/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 4.2721e-07 - y_loss: 1.4095e-08 - Grad__2_loss: 1.3301e-07 - lr: 1.0000e-05 - time: 1.3908 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 57: [2.0, 3.0]\n",
            "Epoch 57/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 4.1154e-07 - y_loss: 1.1469e-08 - Grad__2_loss: 1.2954e-07 - lr: 1.0000e-05 - time: 1.3305 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 58: [2.0, 3.0]\n",
            "Epoch 58/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 4.0184e-07 - y_loss: 1.0696e-08 - Grad__2_loss: 1.2682e-07 - lr: 1.0000e-05 - time: 1.3878 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 59: [2.0, 3.0]\n",
            "Epoch 59/200\n",
            "313/313 [==============================] - 3s 9ms/step - batch: 156.0000 - size: 31.9489 - loss: 3.9916e-07 - y_loss: 1.1093e-08 - Grad__2_loss: 1.2566e-07 - lr: 1.0000e-05 - time: 2.8684 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 60: [2.0, 3.0]\n",
            "Epoch 60/200\n",
            "313/313 [==============================] - 2s 8ms/step - batch: 156.0000 - size: 31.9489 - loss: 4.0833e-07 - y_loss: 1.6498e-08 - Grad__2_loss: 1.2511e-07 - lr: 1.0000e-05 - time: 2.4111 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 61: [2.0, 3.0]\n",
            "Epoch 61/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 3.8885e-07 - y_loss: 1.1297e-08 - Grad__2_loss: 1.2209e-07 - lr: 1.0000e-05 - time: 1.3774 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 62: [2.0, 3.0]\n",
            "Epoch 62/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 3.8243e-07 - y_loss: 1.0679e-08 - Grad__2_loss: 1.2036e-07 - lr: 1.0000e-05 - time: 1.3234 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 63: [2.0, 3.0]\n",
            "Epoch 63/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 3.8542e-07 - y_loss: 1.3276e-08 - Grad__2_loss: 1.1962e-07 - lr: 1.0000e-05 - time: 1.2687 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 64: [2.0, 3.0]\n",
            "Epoch 64/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 3.7307e-07 - y_loss: 1.0705e-08 - Grad__2_loss: 1.1722e-07 - lr: 1.0000e-05 - time: 1.3249 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 65: [2.0, 3.0]\n",
            "Epoch 65/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 3.6507e-07 - y_loss: 1.0051e-08 - Grad__2_loss: 1.1499e-07 - lr: 1.0000e-05 - time: 1.2182 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 66: [2.0, 3.0]\n",
            "Epoch 66/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 3.7170e-07 - y_loss: 1.2884e-08 - Grad__2_loss: 1.1531e-07 - lr: 1.0000e-05 - time: 1.3157 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 67: [2.0, 3.0]\n",
            "Epoch 67/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 3.6510e-07 - y_loss: 1.1868e-08 - Grad__2_loss: 1.1379e-07 - lr: 1.0000e-05 - time: 1.3436 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 68: [2.0, 3.0]\n",
            "Epoch 68/200\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 3.5042e-07 - y_loss: 8.6042e-09 - Grad__2_loss: 1.1107e-07 - lr: 1.0000e-05 - time: 2.0584 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 69: [2.0, 3.0]\n",
            "Epoch 69/200\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 3.5652e-07 - y_loss: 1.1468e-08 - Grad__2_loss: 1.1119e-07 - lr: 1.0000e-05 - time: 2.0450 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 70: [2.0, 3.0]\n",
            "Epoch 70/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 3.4965e-07 - y_loss: 9.7714e-09 - Grad__2_loss: 1.1004e-07 - lr: 1.0000e-05 - time: 1.3103 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 71: [2.0, 3.0]\n",
            "Epoch 71/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 3.4373e-07 - y_loss: 1.0194e-08 - Grad__2_loss: 1.0778e-07 - lr: 1.0000e-05 - time: 1.2920 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 72: [2.0, 3.0]\n",
            "Epoch 72/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 3.4178e-07 - y_loss: 1.0235e-08 - Grad__2_loss: 1.0710e-07 - lr: 1.0000e-05 - time: 1.2677 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 73: [2.0, 3.0]\n",
            "Epoch 73/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 3.3710e-07 - y_loss: 9.9863e-09 - Grad__2_loss: 1.0571e-07 - lr: 1.0000e-05 - time: 1.2550 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 74: [2.0, 3.0]\n",
            "Epoch 74/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 3.3813e-07 - y_loss: 1.0553e-08 - Grad__2_loss: 1.0568e-07 - lr: 1.0000e-05 - time: 1.3456 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 75: [2.0, 3.0]\n",
            "Epoch 75/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 3.3277e-07 - y_loss: 1.0359e-08 - Grad__2_loss: 1.0402e-07 - lr: 1.0000e-05 - time: 1.2760 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 76: [2.0, 3.0]\n",
            "Epoch 76/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 3.3034e-07 - y_loss: 1.0032e-08 - Grad__2_loss: 1.0343e-07 - lr: 1.0000e-05 - time: 1.2855 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 77: [2.0, 3.0]\n",
            "Epoch 77/200\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 3.2731e-07 - y_loss: 1.0354e-08 - Grad__2_loss: 1.0220e-07 - lr: 1.0000e-05 - time: 1.6970 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 78: [2.0, 3.0]\n",
            "Epoch 78/200\n",
            "313/313 [==============================] - 2s 7ms/step - batch: 156.0000 - size: 31.9489 - loss: 3.2175e-07 - y_loss: 9.6318e-09 - Grad__2_loss: 1.0083e-07 - lr: 1.0000e-05 - time: 2.3274 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 79: [2.0, 3.0]\n",
            "Epoch 79/200\n",
            "313/313 [==============================] - 3s 10ms/step - batch: 156.0000 - size: 31.9489 - loss: 3.2604e-07 - y_loss: 1.2745e-08 - Grad__2_loss: 1.0018e-07 - lr: 1.0000e-05 - time: 3.2956 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 80: [2.0, 3.0]\n",
            "Epoch 80/200\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 3.1184e-07 - y_loss: 9.1997e-09 - Grad__2_loss: 9.7813e-08 - lr: 1.0000e-05 - time: 1.5526 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 81: [2.0, 3.0]\n",
            "Epoch 81/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 3.1559e-07 - y_loss: 1.0357e-08 - Grad__2_loss: 9.8293e-08 - lr: 1.0000e-05 - time: 1.3014 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 82: [2.0, 3.0]\n",
            "Epoch 82/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 3.1117e-07 - y_loss: 9.5477e-09 - Grad__2_loss: 9.7358e-08 - lr: 1.0000e-05 - time: 1.2285 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 83: [2.0, 3.0]\n",
            "Epoch 83/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 3.1042e-07 - y_loss: 1.0382e-08 - Grad__2_loss: 9.6551e-08 - lr: 1.0000e-05 - time: 1.3332 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 84: [2.0, 3.0]\n",
            "Epoch 84/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.9998e-07 - y_loss: 8.9722e-09 - Grad__2_loss: 9.4013e-08 - lr: 1.0000e-05 - time: 1.2327 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 85: [2.0, 3.0]\n",
            "Epoch 85/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 3.0145e-07 - y_loss: 1.0165e-08 - Grad__2_loss: 9.3707e-08 - lr: 1.0000e-05 - time: 1.3768 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 86: [2.0, 3.0]\n",
            "Epoch 86/200\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 3.0222e-07 - y_loss: 9.9552e-09 - Grad__2_loss: 9.4103e-08 - lr: 1.0000e-05 - time: 2.0435 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 87: [2.0, 3.0]\n",
            "Epoch 87/200\n",
            "313/313 [==============================] - 2s 7ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.9325e-07 - y_loss: 9.6062e-09 - Grad__2_loss: 9.1347e-08 - lr: 1.0000e-05 - time: 2.1450 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 88: [2.0, 3.0]\n",
            "Epoch 88/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.9177e-07 - y_loss: 8.7795e-09 - Grad__2_loss: 9.1403e-08 - lr: 1.0000e-05 - time: 1.3428 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 89: [2.0, 3.0]\n",
            "Epoch 89/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.9177e-07 - y_loss: 9.1163e-09 - Grad__2_loss: 9.1181e-08 - lr: 1.0000e-05 - time: 1.3340 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 90: [2.0, 3.0]\n",
            "Epoch 90/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.8646e-07 - y_loss: 8.7595e-09 - Grad__2_loss: 8.9646e-08 - lr: 1.0000e-05 - time: 1.3158 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 91: [2.0, 3.0]\n",
            "Epoch 91/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.8398e-07 - y_loss: 8.6690e-09 - Grad__2_loss: 8.8880e-08 - lr: 1.0000e-05 - time: 1.2817 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 92: [2.0, 3.0]\n",
            "Epoch 92/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.8262e-07 - y_loss: 8.3869e-09 - Grad__2_loss: 8.8616e-08 - lr: 1.0000e-05 - time: 1.3475 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 93: [2.0, 3.0]\n",
            "Epoch 93/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.7271e-07 - y_loss: 6.8629e-09 - Grad__2_loss: 8.6329e-08 - lr: 1.0000e-05 - time: 1.3663 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 94: [2.0, 3.0]\n",
            "Epoch 94/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.8655e-07 - y_loss: 1.0738e-08 - Grad__2_loss: 8.8358e-08 - lr: 1.0000e-05 - time: 1.3382 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 95: [2.0, 3.0]\n",
            "Epoch 95/200\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.7596e-07 - y_loss: 8.7602e-09 - Grad__2_loss: 8.6145e-08 - lr: 1.0000e-05 - time: 1.8519 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 96: [2.0, 3.0]\n",
            "Epoch 96/200\n",
            "313/313 [==============================] - 2s 7ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.6804e-07 - y_loss: 7.7885e-09 - Grad__2_loss: 8.4156e-08 - lr: 1.0000e-05 - time: 2.2112 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 97: [2.0, 3.0]\n",
            "Epoch 97/200\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.6591e-07 - y_loss: 7.5124e-09 - Grad__2_loss: 8.3627e-08 - lr: 1.0000e-05 - time: 1.6395 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 98: [2.0, 3.0]\n",
            "Epoch 98/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.6469e-07 - y_loss: 7.7653e-09 - Grad__2_loss: 8.3054e-08 - lr: 1.0000e-05 - time: 1.3560 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 99: [2.0, 3.0]\n",
            "Epoch 99/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.6442e-07 - y_loss: 7.9334e-09 - Grad__2_loss: 8.2852e-08 - lr: 1.0000e-05 - time: 1.2857 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 100: [2.0, 3.0]\n",
            "Epoch 100/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.6465e-07 - y_loss: 8.0817e-09 - Grad__2_loss: 8.2831e-08 - lr: 1.0000e-05 - time: 1.3368 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 101: [2.0, 3.0]\n",
            "Epoch 101/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.6353e-07 - y_loss: 9.0257e-09 - Grad__2_loss: 8.1827e-08 - lr: 1.0000e-05 - time: 1.2662 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 102: [2.0, 3.0]\n",
            "Epoch 102/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.6132e-07 - y_loss: 8.3957e-09 - Grad__2_loss: 8.1510e-08 - lr: 1.0000e-05 - time: 1.3411 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 103: [2.0, 3.0]\n",
            "Epoch 103/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.5802e-07 - y_loss: 8.1623e-09 - Grad__2_loss: 8.0565e-08 - lr: 1.0000e-05 - time: 1.3398 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 104: [2.0, 3.0]\n",
            "Epoch 104/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.5314e-07 - y_loss: 7.7411e-09 - Grad__2_loss: 7.9218e-08 - lr: 1.0000e-05 - time: 1.4430 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 105: [2.0, 3.0]\n",
            "Epoch 105/200\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.5779e-07 - y_loss: 8.8858e-09 - Grad__2_loss: 8.0006e-08 - lr: 1.0000e-05 - time: 2.0393 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 106: [2.0, 3.0]\n",
            "Epoch 106/200\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.4989e-07 - y_loss: 8.0862e-09 - Grad__2_loss: 7.7907e-08 - lr: 1.0000e-05 - time: 1.9818 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 107: [2.0, 3.0]\n",
            "Epoch 107/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.5389e-07 - y_loss: 9.7141e-09 - Grad__2_loss: 7.8155e-08 - lr: 1.0000e-05 - time: 1.3540 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 108: [2.0, 3.0]\n",
            "Epoch 108/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.4758e-07 - y_loss: 8.2356e-09 - Grad__2_loss: 7.7036e-08 - lr: 1.0000e-05 - time: 1.3106 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 109: [2.0, 3.0]\n",
            "Epoch 109/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.4686e-07 - y_loss: 8.8499e-09 - Grad__2_loss: 7.6386e-08 - lr: 1.0000e-05 - time: 1.2902 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 110: [2.0, 3.0]\n",
            "Epoch 110/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.4039e-07 - y_loss: 6.8583e-09 - Grad__2_loss: 7.5559e-08 - lr: 1.0000e-05 - time: 1.2840 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 111: [2.0, 3.0]\n",
            "Epoch 111/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.4048e-07 - y_loss: 7.5492e-09 - Grad__2_loss: 7.5128e-08 - lr: 1.0000e-05 - time: 1.3956 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 112: [2.0, 3.0]\n",
            "Epoch 112/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.3730e-07 - y_loss: 6.9732e-09 - Grad__2_loss: 7.4451e-08 - lr: 1.0000e-05 - time: 1.3237 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 113: [2.0, 3.0]\n",
            "Epoch 113/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.4149e-07 - y_loss: 8.5373e-09 - Grad__2_loss: 7.4806e-08 - lr: 1.0000e-05 - time: 1.3743 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 114: [2.0, 3.0]\n",
            "Epoch 114/200\n",
            "313/313 [==============================] - 2s 7ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.3658e-07 - y_loss: 7.5575e-09 - Grad__2_loss: 7.3820e-08 - lr: 1.0000e-05 - time: 2.2271 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 115: [2.0, 3.0]\n",
            "Epoch 115/200\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.3561e-07 - y_loss: 8.2928e-09 - Grad__2_loss: 7.3007e-08 - lr: 1.0000e-05 - time: 2.0412 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 116: [2.0, 3.0]\n",
            "Epoch 116/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.3386e-07 - y_loss: 7.8355e-09 - Grad__2_loss: 7.2730e-08 - lr: 1.0000e-05 - time: 1.3472 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 117: [2.0, 3.0]\n",
            "Epoch 117/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.3587e-07 - y_loss: 8.5376e-09 - Grad__2_loss: 7.2931e-08 - lr: 1.0000e-05 - time: 1.3048 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 118: [2.0, 3.0]\n",
            "Epoch 118/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.3069e-07 - y_loss: 7.5932e-09 - Grad__2_loss: 7.1833e-08 - lr: 1.0000e-05 - time: 1.3263 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 119: [2.0, 3.0]\n",
            "Epoch 119/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.2478e-07 - y_loss: 6.2949e-09 - Grad__2_loss: 7.0730e-08 - lr: 1.0000e-05 - time: 1.3680 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 120: [2.0, 3.0]\n",
            "Epoch 120/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.2652e-07 - y_loss: 7.9561e-09 - Grad__2_loss: 7.0201e-08 - lr: 1.0000e-05 - time: 1.3182 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 121: [2.0, 3.0]\n",
            "Epoch 121/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.2627e-07 - y_loss: 7.4280e-09 - Grad__2_loss: 7.0472e-08 - lr: 1.0000e-05 - time: 1.3504 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 122: [2.0, 3.0]\n",
            "Epoch 122/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.2431e-07 - y_loss: 6.9955e-09 - Grad__2_loss: 7.0108e-08 - lr: 1.0000e-05 - time: 1.3251 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 123: [2.0, 3.0]\n",
            "Epoch 123/200\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.1930e-07 - y_loss: 6.3724e-09 - Grad__2_loss: 6.8850e-08 - lr: 1.0000e-05 - time: 1.8916 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 124: [2.0, 3.0]\n",
            "Epoch 124/200\n",
            "313/313 [==============================] - 2s 7ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.1474e-07 - y_loss: 5.9958e-09 - Grad__2_loss: 6.7585e-08 - lr: 1.0000e-05 - time: 2.2446 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 125: [2.0, 3.0]\n",
            "Epoch 125/200\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.2174e-07 - y_loss: 7.6533e-09 - Grad__2_loss: 6.8812e-08 - lr: 1.0000e-05 - time: 1.5110 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 126: [2.0, 3.0]\n",
            "Epoch 126/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.1815e-07 - y_loss: 7.3564e-09 - Grad__2_loss: 6.7813e-08 - lr: 1.0000e-05 - time: 1.4227 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 127: [2.0, 3.0]\n",
            "Epoch 127/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.1404e-07 - y_loss: 6.1609e-09 - Grad__2_loss: 6.7241e-08 - lr: 1.0000e-05 - time: 1.3851 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 128: [2.0, 3.0]\n",
            "Epoch 128/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.1058e-07 - y_loss: 6.1884e-09 - Grad__2_loss: 6.6066e-08 - lr: 1.0000e-05 - time: 1.2719 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 129: [2.0, 3.0]\n",
            "Epoch 129/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.1354e-07 - y_loss: 7.3043e-09 - Grad__2_loss: 6.6312e-08 - lr: 1.0000e-05 - time: 1.2868 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 130: [2.0, 3.0]\n",
            "Epoch 130/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.1002e-07 - y_loss: 6.6334e-09 - Grad__2_loss: 6.5584e-08 - lr: 1.0000e-05 - time: 1.3152 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 131: [2.0, 3.0]\n",
            "Epoch 131/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.1174e-07 - y_loss: 7.4977e-09 - Grad__2_loss: 6.5581e-08 - lr: 1.0000e-05 - time: 1.3284 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 132: [2.0, 3.0]\n",
            "Epoch 132/200\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.0729e-07 - y_loss: 6.3753e-09 - Grad__2_loss: 6.4845e-08 - lr: 1.0000e-05 - time: 1.6252 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 133: [2.0, 3.0]\n",
            "Epoch 133/200\n",
            "313/313 [==============================] - 2s 7ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.0798e-07 - y_loss: 7.1584e-09 - Grad__2_loss: 6.4553e-08 - lr: 1.0000e-05 - time: 2.2083 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 134: [2.0, 3.0]\n",
            "Epoch 134/200\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.0552e-07 - y_loss: 6.7452e-09 - Grad__2_loss: 6.4010e-08 - lr: 1.0000e-05 - time: 1.6657 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 135: [2.0, 3.0]\n",
            "Epoch 135/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.0459e-07 - y_loss: 6.7830e-09 - Grad__2_loss: 6.3675e-08 - lr: 1.0000e-05 - time: 1.3141 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 136: [2.0, 3.0]\n",
            "Epoch 136/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.0160e-07 - y_loss: 6.5381e-09 - Grad__2_loss: 6.2840e-08 - lr: 1.0000e-05 - time: 1.4025 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 137: [2.0, 3.0]\n",
            "Epoch 137/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.0017e-07 - y_loss: 5.9729e-09 - Grad__2_loss: 6.2740e-08 - lr: 1.0000e-05 - time: 1.4448 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 138: [2.0, 3.0]\n",
            "Epoch 138/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.0355e-07 - y_loss: 6.9585e-09 - Grad__2_loss: 6.3212e-08 - lr: 1.0000e-05 - time: 1.3537 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 139: [2.0, 3.0]\n",
            "Epoch 139/200\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.0049e-07 - y_loss: 6.9362e-09 - Grad__2_loss: 6.2206e-08 - lr: 1.0000e-05 - time: 1.7070 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 140: [2.0, 3.0]\n",
            "Epoch 140/200\n",
            "313/313 [==============================] - 2s 8ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.0171e-07 - y_loss: 7.7870e-09 - Grad__2_loss: 6.2045e-08 - lr: 1.0000e-05 - time: 2.4492 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 141: [2.0, 3.0]\n",
            "Epoch 141/200\n",
            "313/313 [==============================] - 2s 7ms/step - batch: 156.0000 - size: 31.9489 - loss: 2.0139e-07 - y_loss: 7.4500e-09 - Grad__2_loss: 6.2163e-08 - lr: 1.0000e-05 - time: 2.2631 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 142: [2.0, 3.0]\n",
            "Epoch 142/200\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.9948e-07 - y_loss: 7.9481e-09 - Grad__2_loss: 6.1196e-08 - lr: 1.0000e-05 - time: 1.8523 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 143: [2.0, 3.0]\n",
            "Epoch 143/200\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.9590e-07 - y_loss: 6.7789e-09 - Grad__2_loss: 6.0782e-08 - lr: 1.0000e-05 - time: 1.5274 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 144: [2.0, 3.0]\n",
            "Epoch 144/200\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.9540e-07 - y_loss: 6.6805e-09 - Grad__2_loss: 6.0679e-08 - lr: 1.0000e-05 - time: 1.5038 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 145: [2.0, 3.0]\n",
            "Epoch 145/200\n",
            "313/313 [==============================] - 1s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.9723e-07 - y_loss: 7.4912e-09 - Grad__2_loss: 6.0750e-08 - lr: 1.0000e-05 - time: 1.4630 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 146: [2.0, 3.0]\n",
            "Epoch 146/200\n",
            "313/313 [==============================] - 1s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.9261e-07 - y_loss: 6.5530e-09 - Grad__2_loss: 5.9836e-08 - lr: 1.0000e-05 - time: 1.4455 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 147: [2.0, 3.0]\n",
            "Epoch 147/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.8714e-07 - y_loss: 5.8299e-09 - Grad__2_loss: 5.8494e-08 - lr: 1.0000e-05 - time: 1.4473 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 148: [2.0, 3.0]\n",
            "Epoch 148/200\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.9177e-07 - y_loss: 6.7234e-09 - Grad__2_loss: 5.9442e-08 - lr: 1.0000e-05 - time: 1.5400 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 149: [2.0, 3.0]\n",
            "Epoch 149/200\n",
            "313/313 [==============================] - 2s 7ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.8629e-07 - y_loss: 6.2646e-09 - Grad__2_loss: 5.7920e-08 - lr: 1.0000e-05 - time: 2.2364 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 150: [2.0, 3.0]\n",
            "Epoch 150/200\n",
            "313/313 [==============================] - 2s 7ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.8845e-07 - y_loss: 6.4758e-09 - Grad__2_loss: 5.8501e-08 - lr: 1.0000e-05 - time: 2.2655 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 151: [2.0, 3.0]\n",
            "Epoch 151/200\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.8759e-07 - y_loss: 6.6921e-09 - Grad__2_loss: 5.8070e-08 - lr: 1.0000e-05 - time: 1.6160 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 152: [2.0, 3.0]\n",
            "Epoch 152/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.8827e-07 - y_loss: 6.9984e-09 - Grad__2_loss: 5.8091e-08 - lr: 1.0000e-05 - time: 1.4355 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 153: [2.0, 3.0]\n",
            "Epoch 153/200\n",
            "313/313 [==============================] - 1s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.8003e-07 - y_loss: 5.3214e-09 - Grad__2_loss: 5.6461e-08 - lr: 1.0000e-05 - time: 1.4916 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 154: [2.0, 3.0]\n",
            "Epoch 154/200\n",
            "313/313 [==============================] - 1s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.8376e-07 - y_loss: 6.2958e-09 - Grad__2_loss: 5.7055e-08 - lr: 1.0000e-05 - time: 1.4662 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 155: [2.0, 3.0]\n",
            "Epoch 155/200\n",
            "313/313 [==============================] - 1s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.8669e-07 - y_loss: 7.0289e-09 - Grad__2_loss: 5.7544e-08 - lr: 1.0000e-05 - time: 1.4978 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 156: [2.0, 3.0]\n",
            "Epoch 156/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.8472e-07 - y_loss: 7.7580e-09 - Grad__2_loss: 5.6402e-08 - lr: 1.0000e-05 - time: 1.4129 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 157: [2.0, 3.0]\n",
            "Epoch 157/200\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.7674e-07 - y_loss: 5.4588e-09 - Grad__2_loss: 5.5273e-08 - lr: 1.0000e-05 - time: 1.5693 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 158: [2.0, 3.0]\n",
            "Epoch 158/200\n",
            "313/313 [==============================] - 2s 7ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.7809e-07 - y_loss: 6.0045e-09 - Grad__2_loss: 5.5360e-08 - lr: 1.0000e-05 - time: 2.2377 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 159: [2.0, 3.0]\n",
            "Epoch 159/200\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.7810e-07 - y_loss: 6.4605e-09 - Grad__2_loss: 5.5061e-08 - lr: 1.0000e-05 - time: 1.9781 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 160: [2.0, 3.0]\n",
            "Epoch 160/200\n",
            "313/313 [==============================] - 1s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.7724e-07 - y_loss: 5.8633e-09 - Grad__2_loss: 5.5171e-08 - lr: 1.0000e-05 - time: 1.4697 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 161: [2.0, 3.0]\n",
            "Epoch 161/200\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.7322e-07 - y_loss: 5.4906e-09 - Grad__2_loss: 5.4078e-08 - lr: 1.0000e-05 - time: 1.5429 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 162: [2.0, 3.0]\n",
            "Epoch 162/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.8010e-07 - y_loss: 7.1793e-09 - Grad__2_loss: 5.5247e-08 - lr: 1.0000e-05 - time: 1.4479 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 163: [2.0, 3.0]\n",
            "Epoch 163/200\n",
            "313/313 [==============================] - 1s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.7640e-07 - y_loss: 5.7146e-09 - Grad__2_loss: 5.4992e-08 - lr: 1.0000e-05 - time: 1.4673 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 164: [2.0, 3.0]\n",
            "Epoch 164/200\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.7209e-07 - y_loss: 5.6119e-09 - Grad__2_loss: 5.3621e-08 - lr: 1.0000e-05 - time: 1.5539 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 165: [2.0, 3.0]\n",
            "Epoch 165/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.7152e-07 - y_loss: 5.8078e-09 - Grad__2_loss: 5.3301e-08 - lr: 1.0000e-05 - time: 1.4528 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 166: [2.0, 3.0]\n",
            "Epoch 166/200\n",
            "313/313 [==============================] - 2s 7ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.6829e-07 - y_loss: 4.9634e-09 - Grad__2_loss: 5.2788e-08 - lr: 1.0000e-05 - time: 2.1959 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 167: [2.0, 3.0]\n",
            "Epoch 167/200\n",
            "313/313 [==============================] - 2s 8ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.7151e-07 - y_loss: 6.1463e-09 - Grad__2_loss: 5.3073e-08 - lr: 1.0000e-05 - time: 2.3875 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 168: [2.0, 3.0]\n",
            "Epoch 168/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.7074e-07 - y_loss: 6.3202e-09 - Grad__2_loss: 5.2699e-08 - lr: 1.0000e-05 - time: 1.3890 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 169: [2.0, 3.0]\n",
            "Epoch 169/200\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.6673e-07 - y_loss: 5.2449e-09 - Grad__2_loss: 5.2080e-08 - lr: 1.0000e-05 - time: 1.5163 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 170: [2.0, 3.0]\n",
            "Epoch 170/200\n",
            "313/313 [==============================] - 1s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.7260e-07 - y_loss: 7.1606e-09 - Grad__2_loss: 5.2760e-08 - lr: 1.0000e-05 - time: 1.4959 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 171: [2.0, 3.0]\n",
            "Epoch 171/200\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.6997e-07 - y_loss: 6.2889e-09 - Grad__2_loss: 5.2464e-08 - lr: 1.0000e-05 - time: 1.7291 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 172: [2.0, 3.0]\n",
            "Epoch 172/200\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.6850e-07 - y_loss: 6.3337e-09 - Grad__2_loss: 5.1944e-08 - lr: 1.0000e-05 - time: 1.8925 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 173: [2.0, 3.0]\n",
            "Epoch 173/200\n",
            "313/313 [==============================] - 2s 7ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.6584e-07 - y_loss: 6.0752e-09 - Grad__2_loss: 5.1230e-08 - lr: 1.0000e-05 - time: 2.2380 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 174: [2.0, 3.0]\n",
            "Epoch 174/200\n",
            "313/313 [==============================] - 3s 8ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.6521e-07 - y_loss: 5.5560e-09 - Grad__2_loss: 5.1368e-08 - lr: 1.0000e-05 - time: 2.5345 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 175: [2.0, 3.0]\n",
            "Epoch 175/200\n",
            "313/313 [==============================] - 2s 7ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.5990e-07 - y_loss: 4.4343e-09 - Grad__2_loss: 5.0343e-08 - lr: 1.0000e-05 - time: 2.0667 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 176: [2.0, 3.0]\n",
            "Epoch 176/200\n",
            "313/313 [==============================] - 1s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.6274e-07 - y_loss: 5.6498e-09 - Grad__2_loss: 5.0479e-08 - lr: 1.0000e-05 - time: 1.4690 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 177: [2.0, 3.0]\n",
            "Epoch 177/200\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.6363e-07 - y_loss: 5.8708e-09 - Grad__2_loss: 5.0629e-08 - lr: 1.0000e-05 - time: 1.5992 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 178: [2.0, 3.0]\n",
            "Epoch 178/200\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.6439e-07 - y_loss: 6.4979e-09 - Grad__2_loss: 5.0465e-08 - lr: 1.0000e-05 - time: 1.5826 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 179: [2.0, 3.0]\n",
            "Epoch 179/200\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.5854e-07 - y_loss: 5.2044e-09 - Grad__2_loss: 4.9378e-08 - lr: 1.0000e-05 - time: 1.6418 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 180: [2.0, 3.0]\n",
            "Epoch 180/200\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.6203e-07 - y_loss: 5.9933e-09 - Grad__2_loss: 5.0016e-08 - lr: 1.0000e-05 - time: 1.6033 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 181: [2.0, 3.0]\n",
            "Epoch 181/200\n",
            "313/313 [==============================] - 1s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.6204e-07 - y_loss: 5.9521e-09 - Grad__2_loss: 5.0047e-08 - lr: 1.0000e-05 - time: 1.4663 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 182: [2.0, 3.0]\n",
            "Epoch 182/200\n",
            "313/313 [==============================] - 2s 7ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.5591e-07 - y_loss: 5.1335e-09 - Grad__2_loss: 4.8548e-08 - lr: 1.0000e-05 - time: 2.1593 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 183: [2.0, 3.0]\n",
            "Epoch 183/200\n",
            "313/313 [==============================] - 2s 8ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.5813e-07 - y_loss: 5.4622e-09 - Grad__2_loss: 4.9070e-08 - lr: 1.0000e-05 - time: 2.4091 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 184: [2.0, 3.0]\n",
            "Epoch 184/200\n",
            "313/313 [==============================] - 1s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.5653e-07 - y_loss: 5.0962e-09 - Grad__2_loss: 4.8778e-08 - lr: 1.0000e-05 - time: 1.4886 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 185: [2.0, 3.0]\n",
            "Epoch 185/200\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.5824e-07 - y_loss: 6.1215e-09 - Grad__2_loss: 4.8665e-08 - lr: 1.0000e-05 - time: 1.5413 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 186: [2.0, 3.0]\n",
            "Epoch 186/200\n",
            "313/313 [==============================] - 1s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.5799e-07 - y_loss: 5.6717e-09 - Grad__2_loss: 4.8881e-08 - lr: 1.0000e-05 - time: 1.4748 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 187: [2.0, 3.0]\n",
            "Epoch 187/200\n",
            "313/313 [==============================] - 1s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.5733e-07 - y_loss: 5.8757e-09 - Grad__2_loss: 4.8526e-08 - lr: 1.0000e-05 - time: 1.4708 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 188: [2.0, 3.0]\n",
            "Epoch 188/200\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.5530e-07 - y_loss: 5.4191e-09 - Grad__2_loss: 4.8153e-08 - lr: 1.0000e-05 - time: 1.4350 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 189: [2.0, 3.0]\n",
            "Epoch 189/200\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.5467e-07 - y_loss: 5.2968e-09 - Grad__2_loss: 4.8025e-08 - lr: 1.0000e-05 - time: 1.5898 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 190: [2.0, 3.0]\n",
            "Epoch 190/200\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.5044e-07 - y_loss: 4.6494e-09 - Grad__2_loss: 4.7048e-08 - lr: 1.0000e-05 - time: 1.9895 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 191: [2.0, 3.0]\n",
            "Epoch 191/200\n",
            "313/313 [==============================] - 2s 8ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.5140e-07 - y_loss: 5.4269e-09 - Grad__2_loss: 4.6848e-08 - lr: 1.0000e-05 - time: 2.4553 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 192: [2.0, 3.0]\n",
            "Epoch 192/200\n",
            "313/313 [==============================] - 2s 7ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.5165e-07 - y_loss: 4.9977e-09 - Grad__2_loss: 4.7218e-08 - lr: 1.0000e-05 - time: 2.1013 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 193: [2.0, 3.0]\n",
            "Epoch 193/200\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.5585e-07 - y_loss: 6.4151e-09 - Grad__2_loss: 4.7674e-08 - lr: 1.0000e-05 - time: 1.6285 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 194: [2.0, 3.0]\n",
            "Epoch 194/200\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.4873e-07 - y_loss: 4.5690e-09 - Grad__2_loss: 4.6530e-08 - lr: 1.0000e-05 - time: 1.5815 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 195: [2.0, 3.0]\n",
            "Epoch 195/200\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.4965e-07 - y_loss: 5.2824e-09 - Grad__2_loss: 4.6363e-08 - lr: 1.0000e-05 - time: 1.6920 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 196: [2.0, 3.0]\n",
            "Epoch 196/200\n",
            "313/313 [==============================] - 1s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.4683e-07 - y_loss: 5.1023e-09 - Grad__2_loss: 4.5542e-08 - lr: 1.0000e-05 - time: 1.4994 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 197: [2.0, 3.0]\n",
            "Epoch 197/200\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.4791e-07 - y_loss: 5.2378e-09 - Grad__2_loss: 4.5812e-08 - lr: 1.0000e-05 - time: 1.5319 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 198: [2.0, 3.0]\n",
            "Epoch 198/200\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.5064e-07 - y_loss: 5.9461e-09 - Grad__2_loss: 4.6250e-08 - lr: 1.0000e-05 - time: 1.7823 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 199: [2.0, 3.0]\n",
            "Epoch 199/200\n",
            "313/313 [==============================] - 2s 8ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.4975e-07 - y_loss: 5.5509e-09 - Grad__2_loss: 4.6217e-08 - lr: 1.0000e-05 - time: 2.3819 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "\n",
            "+ adaptive_weights at epoch 200: [2.0, 3.0]\n",
            "Epoch 200/200\n",
            "313/313 [==============================] - 2s 7ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.4971e-07 - y_loss: 5.7537e-09 - Grad__2_loss: 4.6067e-08 - lr: 1.0000e-05 - time: 2.0842 - loss_weight_0: 2.0000 - loss_weight_1: 3.0000\n",
            "Training finished in 323.6403181552887s. \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAGdCAYAAAAfTAk2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABbhElEQVR4nO3dd3gU5cLG4d9uKi2hJwRCk94hQAjVkgMoIhxRQZEmAiJVqrGAioICotKLSFEQsOBBFBRReiAQinQBaQKhJ4EAaTvfH4eT7+RIi2bzbjbPfV1zaWbfmX1mKfMwO8VmWZaFiIiIiBuxmw4gIiIiktlUcERERMTtqOCIiIiI21HBEREREbejgiMiIiJuRwVHRERE3I4KjoiIiLgdFRwRERFxO56mA5jgcDg4ffo0+fLlw2azmY4jIiIi98CyLK5cuUJQUBB2+52P0eTIgnP69GmCg4NNxxAREZG/4OTJk5QoUeKOY3JkwcmXLx/w7w/Iz8/PcBoRERG5F/Hx8QQHB6ftx+8kRxac/3wt5efnp4IjIiKSzdzL6SU6yVhERETcjgqOiIiIuB0VHBEREXE7KjgiIiLidlRwRERExO2o4IiIiIjbUcERERERt6OCIyIiIm5HBUdERETcjlMLzrp162jdujVBQUHYbDa++eabuy6zZs0a6tSpg4+PD+XKlWPu3Ll/GjNlyhRKly6Nr68voaGhREVFZX54ERERybacWnASEhKoWbMmU6ZMuafxR48epVWrVjzwwAPs3LmTgQMH8vzzz/PDDz+kjVm8eDGDBg1i5MiRbN++nZo1a9KiRQvOnTvnrM0QERGRbMZmWZaVJW9ks7F06VLatm172zHDhw/nu+++Y8+ePWnzOnToQGxsLCtXrgQgNDSUevXqMXnyZAAcDgfBwcH069ePl19++Z6yxMfH4+/vT1xcnJ5FJSIikk1kZP/tUg/bjIyMJDw8PN28Fi1aMHDgQACSkpKIjo4mIiIi7XW73U54eDiRkZG3XW9iYiKJiYlpP8fHx2ducMmWkq9d49gPP3BxyxYO5c3LkZQUrl+/TuELF6i3Zw9WwYJ4Fi2Kb7lyFHvwQYJCQ7F7utQfGRERuQ2X+ts6JiaGgICAdPMCAgKIj4/n+vXrXL58mdTU1FuOOXDgwG3XO2bMGN58802nZJbsI/7UKfbPmMH1b78l8MAByt64QXmgPDATmHNzXHNg6P8uPGIEV4FD+fOz/+GHKfHCCzRs2BBPFR4REZeUI/52joiIYNCgQWk/x8fHExwcbDCRZJUbN278+2vPDz5g+MaNhP7P6/HAiTx5qFylCr3q1CFPnjwUjY1lzc6deMbF4X3lCgXi4iiVmEheoHZsLGM//5xFn39O0aJFea5FC55u0IDqL7yAza6LEkVEXIVLFZzAwEDOnj2bbt7Zs2fx8/MjV65ceHh44OHhccsxgYGBt12vj48PPj4+Tsksrunc7t0smTyZt5Yu5fz58xQAIoATnp4cq1ABrxYtCH78cYo3bEg1u51qd1lf8rVrHF61itNLluB37RoF163794ntn35KjU8/5bfBg4l5/HFCPvyQPEWKZMEWiojInbjUPznDwsJYvXp1unmrVq0iLCwMAG9vb0JCQtKNcTgcrF69Om2M5Gxnd+5kbbVq+NeoQb2ZMzl//jwlSpSg5/DhHPn+e4ITE2m6dy9hEyZQonHjez7q4pU7N+XatKHpggXMWLqUmJgYfvjhB+rVrs01oMKNGzRduJCEwEDWtG3L9UuXnLuhIiJyZ5YTXblyxdqxY4e1Y8cOC7AmTJhg7dixwzp+/LhlWZb18ssvW506dUob//vvv1u5c+e2hg4dau3fv9+aMmWK5eHhYa1cuTJtzKJFiywfHx9r7ty51r59+6yePXta+fPnt2JiYu45V1xcnAVYcXFxmbexYlTcyZPWz2Fh1lWwrJvT7rx5raVz5ljJyclOfe/Yo0etNW3aWCc8PdPe+4zdbq177jkrNSXFqe8tIpKTZGT/7dSC88svv1jAn6YuXbpYlmVZXbp0sZo1a/anZWrVqmV5e3tbZcuWtebMmfOn9U6aNMkqWbKk5e3tbdWvX9/avHlzhnKp4LgPR2qqtXHIEOu03Z6u2Oz44IMsz5KUkGCt69zZOunhYVlgLQErLCzM2r59e5ZnERFxRxnZf2fZfXBcie6D4x5OnTrFx23bMnLbNgCOe3lxdsgQ6r39ttETfpOuXiWyQwd6/fwzB69fx26389qAAbzy5pv45MtnLJeISHaXkf23S52DI3Kvvv76a2rUqMGb27axzmZjTePGBJw9S/3Ro41fzeSdNy/Nli9n9aFDtG/fHofDQfkPPuBY0aL89uWXRrOJiOQUKjiSrVy7cIFlderQsV07Ll26RJ2QEIr8+iv3r1+Pb4ECpuOlU7x4cRYtWsR3s2fT0maj4o0blHrySdZ27IjlcJiOJyLi1lRwJNv4Y9MmjpcsyWM7djAeePnll9m0aROVq93tIm+zHnnuOaxff2VLQAA+QLOFC9lYoQLXLlwwHU1ExG2p4Ei2sHPiRHwaN6by9etcsNloOHYsY8aMwdvb23S0e1KkWjXqnz7N2kceIRVofOQIJ4KDOb1li+loIiJuSQVHXN66bt2oOmAARSyLA7lykbhhA7WH/ulhCi7PZrfT7Lvv2DV+POdtNirduEF848bsiI42HU1ExO2o4IjLshwOfv7HP2g6dy5ewKZSpSh54gTFGzY0He1vqTN4MEkbNrDP15deKSk0vf9+VqxYYTqWiIhbUcERl5Samspr3btT56efAFjTsCFhv/9O7sKFDSfLHMUbNiTo1Ck8H3yQq1ev0rp1a5bMmmU6loiI21DBEZeTkpJC586dGT13Lo8Ba9u14/6NG41f/p3Z8hcsyIoVK+jUqRNVUlN5oGdP1nXrZjqWiIhbcK89hmR7KYmJDPvnP1m4cCFeXl70XbyYZm587xhvb2/mzp3L2Nq1KQI0nTuXtU89ZTqWiEi2p4IjLiMlMZEtFSvy+vLl1Pf05IsvvuCpHLCzt9vttNi2jTV16gDQ7IsvWPvkk4ZTiYhkbyo44hJSk5PZXKkSjY4fJy8wcehQ2rRpYzpWlrHZ7TTbupU1N0+gbvbll6x//nnDqUREsi8VHDHOcjjYEBJC42PHSAZ2vPwyoaNHm46V5Wx2O83Wr2dt7doANJw9m81DhhhOJSKSPangiHFrmjen2e7dOICt/ftTf8wY05GMsdntNN22jfUVKuABXJ8wgR9WrjQdS0Qk21HBEaPWPvssD6xeDcCGJ56g4UcfGU5kns1up+Hu3SyoUYNHLYt2TzzBjh07TMcSEclWVHDEmH8tXUrKggUArG3UiKZffGE4kevw8PbmqW3baBgeTkJCAo8++ih/HDpkOpaISLahgiNG7Nq1i46dOtEK+KxxY5quW2c6ksvx8vLiyy+/pGqVKvQ4fZqEGjWI/+MP07FERLIFFRzJcjHHj9O6dWsSEhJoEh5Oh19+cbub+GUWf39/Vn76Kb3tdireuMGhWrVIuXHDdCwREZenvYpkqRuxsZyrVo0XT56kUoUKLFmyBE9PT9OxXFqJOnW4NG8eCUDIxYtsaNzYdCQREZengiNZxnI42BoSQo2rV3nBZuP7mTMpUKCA6VjZQuVnn2X3zUvG74+OZmOfPoYTiYi4NhUcyTLrOnSgye+/kwIcfe89yjRrZjpSttJg3Li0GwHWnjqVg4sXG04kIuK6VHAkS+yZPZuwm1dJbWzThtpDhxpOlD01+eUXthYuTG4gT8eOXDxxwnQkERGXpIIjTnfx4EEK9OqFN7C5eHGafv216UjZloe3N+Wjojjo5cVrqal07NkTh8NhOpaIiMtRwRGnSk1J4WijRhRPTeWolxdVNm/WFVN/U/4yZUjasoUluXLxww8/MG7cONORRERcjvY04lTvjB7NhIsXOQekLFqEX4kSpiO5heq1azNx4kQA3n/lFXbOn284kYiIa7FZlmWZDpHV4uPj8ff3Jy4uDj8/P9Nx3NaGDRto1qwZDoeDhbNm8bSejp2pLMtieKtW9FuxApuHB3kOHqTAffeZjiUi4jQZ2X/rCI44ReyJE/R7+mkcDgedOnVSuXECm83GazNnkurlRYnUVA41boyl83FERAAVHHECy7LY07Qpy//4gw7FijF58mTTkdyWX4kSXJszh0SgfkwM6zt2NB1JRMQlqOBIptv44os0Pn6cAODVN97Q14BOVqVjRyLbtgUgZNEijq1aZTaQiIgLUMGRTHVi7VqqT58OwMYHHqBaz56GE+UMTb/4gu0FCpAHuPrPf+p5VSKS46ngSKZxpKRw6bHH8Ad+9fOj8YoVpiPlGHZPTwJXrCAOqJaQwJqbR3RERHIqFRzJNOvat6dWfDxXgYLffouHj4/pSDlKUGgou3v14nPgmZ9+Yvv27aYjiYgYkyUFZ8qUKZQuXRpfX19CQ0OJioq67dj7778fm832p6lVq1ZpY7p27fqn11u2bJkVmyK3cWz1aurdvEPxjg4dKNG0qeFEOVOjqVP5ql07zqem0qlTJ65fv246koiIEU4vOIsXL2bQoEGMHDmS7du3U7NmTVq0aMG5c+duOf7rr7/mzJkzadOePXvw8PDgySefTDeuZcuW6cZ9/vnnzt4UuQ2Hw0Gf115jKbAjf34af/aZ6Ug5ls1uZ/r06QQEBLBv3z5m9OtnOpKIiBFOLzgTJkygR48edOvWjSpVqjB9+nRy587NJ598csvxBQsWJDAwMG1atWoVuXPn/lPB8fHxSTeuQIECzt4UuY3Jkyfz/ebN9M6bl4KRkdg8PExHytEKFy7MzEmT+AboO3s2BxYtMh1JRCTLObXgJCUlER0dTXh4+P+/od1OeHg4kZGR97SO2bNn06FDB/LkyZNu/po1ayhatCgVK1akd+/eXLx48bbrSExMJD4+Pt0kmePIrl28PHw4AOPGjaNUpUqGEwnAY08+SZESJfAEeO45XVUlIjmOUwvOhQsXSE1NJSAgIN38gIAAYmJi7rp8VFQUe/bs4fn/uQtuy5YtmT9/PqtXr+a9995j7dq1PPzww6Smpt5yPWPGjMHf3z9tCg4O/usbJWksh4O4++9n4Y0btGvUiJ66JNyllPv+ey7bbFS6fp0Njz9uOo6ISJZy6auoZs+eTfXq1alfv366+R06dOCxxx6jevXqtG3bluXLl7N161bWrFlzy/VEREQQFxeXNp08eTIL0ru/jb17Uyc2lubAB++8g11PCXcpRatXZ89zzwHQYMUKjv34o+FEIiJZx6l7pMKFC+Ph4cHZs2fTzT979iyBgYF3XDYhIYFFixbRvXv3u75P2bJlKVy4MIcPH77l6z4+Pvj5+aWb5O+5+NtvVJo1C4Cohx8muFkzw4nkVhrPnMm2QoXwBeKeegrrNkc5RUTcjVMLjre3NyEhIaxevTptnsPhYPXq1YSFhd1x2S+++ILExESeffbZu77PH3/8wcWLFylWrNjfziz3Zu+jj1LYsjjk40OjL780HUduw2a3E7B0KVeBmnFxbNBDT0Ukh3D6dwqDBg1i1qxZzJs3j/3799O7d28SEhLo1q0bAJ07dyYiIuJPy82ePZu2bdtSqFChdPOvXr3K0KFD2bx5M8eOHWP16tW0adOGcuXK0aJFC2dvjgA7J06k6aFDANyYOBGv3LkNJ5I7CW7ShOhHH+Uw8MFXX93xhHwREXfh6ew3aN++PefPn2fEiBHExMRQq1YtVq5cmXbi8YkTJ/507sbBgwfZsGEDP97inAEPDw9+/fVX5s2bR2xsLEFBQTRv3pxRo0bhozvnOl3ilSvkHToUgPWVK9NEJxZnCw0XLya0bl127N9PkVdeYcaMGaYjiYg4lc2yLMt0iKwWHx+Pv78/cXFxOh8ng6YMHMgjH31EXrsd7yNH8C9d2nQkuUfr16+nadOm2Gw2IjdtIrRBA9ORREQyJCP7b132Ivfs6NGjDJ4+narAjnfeUbnJZpo0aULXZ5+lr2Xh8Y9/kJqYaDqSiIjTqODIPRs8eDCJiYmEPfgg/7h5cz/JXt57+WXestmoe/UqG+/hBH4RkexKBUfuybbx4ymydCledjsTJ07EZrOZjiR/QdGqVdnVvj0ANb/8kvO//mo4kYiIc6jgyF0lX7tG/ldfZQbwdVgYVatWNR1J/obG8+ezJ3du/IED7dqZjiMi4hQqOHJXG595hnJJSVyw2WiiJ4Vnex5eXjBxIgBNDh9m3/z5hhOJiGQ+FRy5o3N79lD7X/8C4ECnTjqx2E1U696dDWXKAJDSty+Ww2E4kYhI5lLBkTs68Pjj+AP7c+em4ccfm44jmajs4sUkAFWvXGHVu++ajiMikqlUcOS29s6bR+ObdyxO/eAD7F5ehhNJZgqqV4+VTzxBLaDHjBlcv37ddCQRkUyjgiO3ZFkWSf37Ywc2li1LNd2x2C09PG8eccHBnDhxgvfff990HBGRTKOCI7f0zTff0DM+nlV2O2UXLTIdR5wkd+7cjB07FoCl77zDmW3bDCcSEckcKjjyJ0lJSQwbNoxtwPpXX6VYvXqmI4kTtW/fnvFlyrDlxg2OPvmk6TgiIplCBUf+5OPJkzl8+DBFixZl6M0Ha4r7stlstHzzTTyBhseOsX/BAtORRET+NhUcSSf2+HHaDh3KWGD0a6+RL18+05EkC1Tt1IkNN28BcL1/f8h5z+AVETejgiPp7GjfniCHg8e9veny/POm40gWKjV/PolAnUuXiB4zxnQcEZG/RQVH0pzcuJGwLVsAuDR8OJ65chlOJFkpuEkTNtWpA0C+UaNwJCcbTiQi8tep4Eia488+iy+wM39+6r7xhuk4YkCNRYuIBSrcuEFkv36m44iI/GUqOALAvgULaHzsGAC+kydjs+u3Rk5UqHx5trdsSSzw7RdfcOPGDdORRET+Eu3FBICrAwcCsLF0aSp17Gg2jBjVYMECGgcG8t6lS0ydOtV0HBGRv0QFR9j8xRdUu3CBZKDE7Nmm44hhuQsWZNA77wDw9ttvc/nyZcOJREQyTgUnh7Msi8Effsh9wPzwcEo9+KDpSOICunTpQtUqVQi9fJk17dubjiMikmEqODncd999x6ZNm4jLlYtH5s83HUdchIeHBzM7d2YF0HLVKs7u3Gk6kohIhqjg5GCOlBQWvvQSAP369aNYsWKGE4krCRs6lN1585ILONi5s+k4IiIZooKTg0UOGsTCw4dZ4unJ8OHDTccRF2Oz20m5ebuABrt3c2rjRrOBREQyQAUnh0q+do2g6dMBKNq0KQULFjScSFxR7cGD2Z4/P97A0eeeMx1HROSeqeDkUJG9elEmOZnzNhshn31mOo64MM933wWgwW+/cXzVKsNpRETujQpODnT98mXKL1wIwL42bcirc2/kDmr06kVUkSJ4Aqd79DAdR0Tknqjg5EBbnnuOYg4Hpzw8aDB3ruk4kg3k/fBD9gLvHz/Ovn37TMcREbkrFZwc5vqlS1RetgyA3zt0wMff33AiyQ6qPPMMI/75T74CRo4caTqOiMhdqeDkMF+++y6JN4/ehN48yVjkXrw1ahQ2m40vv/ySHTt2mI4jInJHKjg5yPXr1xn26aeUByJHjsQ7b17TkSQbqVq1Kl2feoqBwPnHHjMdR0TkjlRwcpAZM2YQExNDUOnSPKb73shfMKJ7d8YDzf/4g/2ffmo6jojIbWVJwZkyZQqlS5fG19eX0NBQoqKibjt27ty52Gy2dJOvr2+6MZZlMWLECIoVK0auXLkIDw/n0KFDzt6MbO3axYscGjkSD+DVV1/F29vbdCTJhkr/4x9Eli0LwJVhwwynERG5PacXnMWLFzNo0CBGjhzJ9u3bqVmzJi1atODcuXO3XcbPz48zZ86kTcePH0/3+tixY5k4cSLTp09ny5Yt5MmThxYtWnDjxg1nb062FdW9O1Pi41nj60tn3XZf/oagKVNIBerHxHDw889NxxERuSWnF5wJEybQo0cPunXrRpUqVZg+fTq5c+fmk08+ue0yNpuNwMDAtCkgICDtNcuy+PDDD3nttddo06YNNWrUYP78+Zw+fZpvvvnG2ZuTLV27eJHK334LgPXkkzp6I39L2ZYtiSxVCoC4wYMNpxERuTWnFpykpCSio6MJDw///ze02wkPDycyMvK2y129epVSpUoRHBxMmzZt2Lt3b9prR48eJSYmJt06/f39CQ0Nve06ExMTiY+PTzflJFHduxPgcPCHhwcNpk0zHUfcQODkyTiA+mfO8NuSJabjiIj8iVMLzoULF0hNTU13BAYgICCAmJiYWy5TsWJFPvnkE/71r3/x2Wef4XA4aNiwIX/88QdA2nIZWeeYMWPw9/dPm4KDg//upmUb/3305ljHjnjlyWM4kbiDco8+SuTNP0eXBw0ynEZE5M9c7iqqsLAwOnfuTK1atWjWrBlff/01RYoUYcaMGX95nREREcTFxaVNJ0+ezMTEru2/j96ETp1qOo64kSITJ/IV8MKpU+mOsoqIuAKnFpzChQvj4eHB2bNn080/e/YsgYGB97QOLy8vateuzeHDhwHSlsvIOn18fPDz80s35QQ3YmPTjt4cfeYZHb2RTFWhbVs+b9eOncDbb79tOo6ISDpOLTje3t6EhISwevXqtHkOh4PVq1cTFhZ2T+tITU1l9+7dFLv5QMgyZcoQGBiYbp3x8fFs2bLlnteZU3wxZQr7//PMKZ17I07w2muvAf++WvLA/v2G04iI/D+nf0U1aNAgZs2axbx589i/fz+9e/cmISGBbt26AdC5c2ciIiLSxr/11lv8+OOP/P7772zfvp1nn32W48eP8/zzzwP/vsJq4MCBvP322yxbtozdu3fTuXNngoKCaNu2rbM3J9tITk7m9VmzeABYMWqUjt6IU9SqVYtuzZszzbK40KqV6TgiImk8nf0G7du35/z584wYMYKYmBhq1arFypUr004SPnHiBHb7//esy5cv06NHD2JiYihQoAAhISFs2rSJKlWqpI0ZNmwYCQkJ9OzZk9jYWBo3bszKlSv/dEPAnGzhwoUcP36cokWL0nHgQNNxxI0Nfe45Kv/4I46jRzn244+Ubt7cdCQREWyWZVmmQ2S1+Ph4/P39iYuLc8vzcVKTkxlfvDjjzp9n6LvvMlyPZRAniwoIoP65c6yvUIEmBw+ajiMibioj+2+Xu4pK/r6oiAiGnz/PLpuN3j16mI4jOYDvqFEAhP72G2e2bjWcRkREBcftWA4H+W9eDn6oUSP8ChY0nEhygho9e7LD3x9v4LdevUzHERFRwXE32955h8rXr5MA1Jg923QcyUFShg4FoO6OHVz67TfDaUQkp1PBcSOWZeE9fjwA20JCKFihguFEkpPUjYhgf65c5AF+1VejImKYCo4b2TV5MjXj40kEKs6caTqO5DA2u50L/frxNtBj1y6uXLliOpKI5GAqOG4k5c03AdhSpQqBdeoYTiM5UcPRo5lfvjyH4+KYqZItIgap4LiJbZs3E33xIglAGT1zSgzx8PBIuy3BhAkTSLxxw3AiEcmpVHDcxJhx43gBGNS+PcHNmpmOIzlYp06deLxwYT47fZqtN+9ALiKS1VRw3MDBgwdZunQpAANGjDCcRnI6b29v+jZpwgNAqcWLSU1MNB1JRHIgFRw3sLlnT2paFq1bt073SAsRU+pNn855m43glBS2DhliOo6I5EAqONncud27ab9uHTuANx9/3HQcEQDyFi3K7gceAKDQxx9jORyGE4lITqOCk83tfeEFfIE9efNSq3Nn03FE0tSeNYurQPkbN4gePdp0HBHJYVRwsrErZ85QOzISgIQ+fbDZ9csprqNA2bJE164NgH3CBMNpRCSn0R4xG4vu3Zv8lsVRLy/q3XzYoYgruW/SJFKAOpcvs3/BAtNxRCQHUcHJppKvXaPc8uUA/NG+PXYvL8OJRP6sRKNGLKtWjU7A6GXLTMcRkRxEBSeb2jJ4MCVSUzlvt1Nv0iTTcURuq+ynn/IZ8PlXX3H8+HHTcUQkh1DByYYsy+K75cs5BewND8c3f37TkURuq1atWoSHh5OamsoHOhdHRLKICk429MMPP/DuH39QLXduan7yiek4Inc19KWX6Af0mDSJ2N9/Nx1HRHIAFZxsaNy4cQB069WLAsWLG04jcnf/aNmSF319qWpZ7HrhBdNxRCQHUMHJZvYsWkTBn3/G28ODgQMHmo4jck9sdjsXunYFoPLq1STGxZkNJCJuTwUnm4kfNowvgH+VL0/JkiVNxxG5Z6Hvv88pDw+KOhxs7d/fdBwRcXMqONnIiTVrCD15EoCyb71lOI1Ixnjlzs1vjzwCQNCiRThSUgwnEhF3poKTjRzt3x8PYFvhwlR48knTcUQyLGTaNGKBsklJRL/xhuE0IuLOVHCyictHjlB3924A7MOGGU4j8tf4FS/O9tBQAHx0/yYRcSIVnGxiZ9++5AEO+vpSe/Bg03FE/rLKU6fyhc1Gz/h4oqKiTMcRETelgpMNJCUkUOnHHwE4/+yzeqimZGvF6tRheadObOH/b3kgIpLZtKfMBr6bPZujDgfn7Hbqvf++6Tgif9uQIUMA+Prrrzl69KjhNCLijlRwXJxlWbw9bx6NgIVDh+Lj52c6ksjfVr16dZ5t3JgPHQ4OPf206Tgi4oZUcFzc+vXr2b59O76+vjx781+9Iu6g/z/+QT+gwZYtxP/xh+k4IuJmVHBcXOSQIRQAunTpQuHChU3HEck0Ia+8whFvb/yAHf36mY4jIm5GBceFHfvpJ4Zu3coJYHCXLqbjiGQqu6cnp27ez6nM8uWkJiUZTiQi7iRLCs6UKVMoXbo0vr6+hIaG3vHS0FmzZtGkSRMKFChAgQIFCA8P/9P4rl27YrPZ0k0tW7Z09mZkueODBmEH9hcpQvmwMNNxRDJd3Y8+4qLNRsmUFLa+9prpOCLiRpxecBYvXsygQYMYOXIk27dvp2bNmrRo0YJz587dcvyaNWt4+umn+eWXX4iMjCQ4OJjmzZtz6tSpdONatmzJmTNn0qbPP//c2ZuSpWKPHiXk5o39PHTujbip3IUK8evN8p57xgzDaUTEndgsy7Kc+QahoaHUq1ePyZMnA+BwOAgODqZfv368/PLLd10+NTWVAgUKMHnyZDp37gz8+whObGws33zzzV/KFB8fj7+/P3Fxcfi56FVJvzzyCA+sWMFvvr6UT0jQvW/EbcXs2EHBOnXwBvbNnUsVfR0rIreRkf23U/eaSUlJREdHEx4e/v9vaLcTHh5OZGTkPa3j2rVrJCcnU7BgwXTz16xZQ9GiRalYsSK9e/fm4sWLt11HYmIi8fHx6SZXlnztGpV++AGAcx07qtyIWwusXZufK1XiXWDKv/5lOo6IuAmn7jkvXLhAamoqAQEB6eYHBAQQExNzT+sYPnw4QUFB6UpSy5YtmT9/PqtXr+a9995j7dq1PPzww6Smpt5yHWPGjMHf3z9tCg4O/usblQWihg2j2H9u7Ddhguk4Ik5XdMECIoCZ337LH7pkXEQygUsfGnj33XdZtGgRS5cuxdfXN21+hw4deOyxx6hevTpt27Zl+fLlbN26lTVr1txyPREREcTFxaVNJ0+ezKItyDjLstj19dckA/vuv1839pMcoU6dOjRt2pSUlJS0r7NFRP4OpxacwoUL4+HhwdmzZ9PNP3v2LIGBgXdcdvz48bz77rv8+OOP1KhR445jy5YtS+HChTl8+PAtX/fx8cHPzy/d5KrWr19PnzNnqOTjQ3WddCk5yKCXXiIcCJswgYT/+TtDRCSjnFpwvL29CQkJYfXq1WnzHA4Hq1evJuwOlz2PHTuWUaNGsXLlSurWrXvX9/njjz+4ePEixYoVy5TcJn3wwQcAhHfpQqFy5QynEck6j7ZqxSwvL9okJxOtG/+JyN/k9K+oBg0axKxZs5g3bx779++nd+/eJCQk0K1bNwA6d+5MRERE2vj33nuP119/nU8++YTSpUsTExNDTEwMV69eBeDq1asMHTqUzZs3c+zYMVavXk2bNm0oV64cLVq0cPbmONXR9es5dPPKsIEDBxrNIpLVPLy8ONamDQAlv/kGR3Ky4UQikp05veC0b9+e8ePHM2LECGrVqsXOnTtZuXJl2onHJ06c4MyZM2njp02bRlJSEk888QTFihVLm8aPHw+Ah4cHv/76K4899hgVKlSge/fuhISEsH79enx8fJy9OU51vG9f9gCflStH5cqVTccRyXJ1J00iFiidnEz0m2+ajiMi2ZjT74PjilzxPjixx4/jUbo0+YDoMWMIuYd7BIm4o59DQ3kwKoqd+fNT6/Jl03FExIW4zH1w5N7tHDCAfMBhHx/qDBtmOo6IMRUnTiQFqBUby8HFi03HEZFsSgXHBaQmJVHmu+8AOPPEE7qxn+RoxUNDibp5r6pzej6ViPxF2pO6gG1vv02plBRibTbq6MZ+Ivi99hp7gHlHj972uXUiIneiguMCPKdMAWBX3brkKVrUcBoR86r16EH3evWYnZrKzJkzTccRkWxIBcew/Zs2EXzpEqnAfTp6I/JvNhv9BwwAYOrUqSTrknERySAVHMM+mj+fksDbjRtTonFj03FEXMaTTz5JmaJFaX3mDBtHjDAdR0SyGRUcgy5fvsz8+fNJBO5/+23TcURcire3N7OrVWMGUEjPpxKRDFLBMeiLceO4cf06NWrUoGnTpqbjiLicah9+SBJQ/epV9s6dazqOiGQjKjiGpCYl8fDYsRwERrRrh81mMx1JxOUUqV6drWXKAHD5rbcMpxGR7EQFx5CtI0YQnJpKIZuNR/r0MR1HxGUVfOMNAOofPcrZnTuNZhGR7EMFxxDvGTMA+LVBA3IVKmQ4jYjrqty5M7vz5cMb2K+H0IrIPVLBMeC3r76iTmwsKUAFXRoucldXunUDoOq6dSTGxxtOIyLZgQqOATGvvgrA1hIlCGrQwHAaEddXb8wYTnl4EGlZfKuTjUXkHqjgZLGLv/1GvYMHAcgTEWE4jUj24JU7NwtffZU2wLvz52NZlulIIuLiVHCyWNTLL5MLOJArF9VfeMF0HJFso2vfvvj4+BAdHU1kZKTpOCLi4lRwslBKSgo9o6JoChzv319PDRfJgCJFitCxY0dKAtGDBpmOIyIuTnvYLPTNN9/wx6lTHChShGY3L30VkXs36IknOAL03rKFM1u3mo4jIi5MBScLzfjgAwB69eqFr6+v4TQi2U/Vhx9mt78/nsBBXTIuIneggpNFDixaxJebNjHOZqO3zr0R+csSe/UCoHpkJNcvXTKcRkRclQpOFjn/+uv4Aw2DgwkqXtx0HJFsq+5bb3HSw4NClkX0kCGm44iIi1LByQLn9+2j3uHDAPi99prhNCLZm6ePD4dbtACgyOefYzkchhOJiCtSwckCewcMwBfYlzs3Vbt3Nx1HJNurNWkSCUDFGzf4dfJk03FExAWp4DhZ8rVrVPz5ZwAud+6sS8NFMkGBsmXZVrky8cCG+fNNxxERF6S9rZNFRURQzOHgnN1O3ffeMx1HxG0UnTaNEkD/HTs4fvy46Tgi4mJUcJwsz5w5AOxr0gQfPz/DaUTcR+Vmzaj/0EM4HA6mTp1qOo6IuBgVHCfaunUrba9c4X27nSoTJ5qOI+J2+vfvD8Cv06Zx7fx5w2lExJWo4DjRpEmTOA7sfOYZitaoYTqOiNtp1aoV3+fOzYorV4h+6SXTcUTEhajgOEnMmTMsWrQI+P9/ZYpI5vLw8CDXP/4BQLEvv9Ql4yKSRgXHSfZ17MgXyck8V60a9erVMx1HxG3V+ugjrgDlEhPZOWGC6Tgi4iJUcJwg6epVqq5dSxug+/33m44j4tbylypFdPXqACS9/77hNCLiKlRwnGDr8OEEOBzE2O3Ue/dd03FE3F7wzT9n9WJiOLlmjdkwIuISsqTgTJkyhdKlS+Pr60toaChRUVF3HP/FF19QqVIlfH19qV69Ot9//3261y3LYsSIERQrVoxcuXIRHh7OoUOHnLkJGeI/bx4ABx54AK88eQynEXF/9z3yCFsLFcIO/K7nU4kIWVBwFi9ezKBBgxg5ciTbt2+nZs2atGjRgnPnzt1y/KZNm3j66afp3r07O3bsoG3btrRt25Y9e/akjRk7diwTJ05k+vTpbNmyhTx58tCiRQtu3Ljh7M25qz2zZ1MtIYFEoOpHH5mOI5Jz3DyZ32/nTq5euWI4jIgYZzlZ/fr1rT59+qT9nJqaagUFBVljxoy55finnnrKatWqVbp5oaGhVq9evSzLsiyHw2EFBgZa48aNS3s9NjbW8vHxsT7//PN7yhQXF2cBVlxcXEY35642lCplWWCtv+++TF+3iNxeanKy1TUoyLKBNXXqVNNxRMQJMrL/duoRnKSkJKKjowkPD0+bZ7fbCQ8PJzIy8pbLREZGphsP0KJFi7TxR48eJSYmJt0Yf39/QkNDb7vOxMRE4uPj003OELN9O/Vv3jK+0JtvOuU9ROTW7J6e1B4+HAuYOHEilmWZjiSSI+3Zs4c2bdrw883nMJri1IJz4cIFUlNTCQgISDc/ICCAmJiYWy4TExNzx/H/+W9G1jlmzBj8/f3TpuDg4L+0PXcz64sv6Ad8V7QolTt2dMp7iMjtde3albx58/L7gQOsv3kfKhHJWpMmTWLZsmVMmzbNaI4ccRVVREQEcXFxadPJkyed8j6devXCb+hQHB9/7JT1i8id+fn5MfaBBzgB5Bo40HQckRzn8tmzfDZ/PgD9+vUzmsWpBadw4cJ4eHhw9uzZdPPPnj1LYGDgLZcJDAy84/j//Dcj6/Tx8cHPzy/d5AylS5dm7NixtG7d2inrF5G7a9m3L0WAeufOcfynn0zHEclRdvbowfYbNxhSsiRNmjQxmsWpBcfb25uQkBBWr16dNs/hcLB69WrCwsJuuUxYWFi68QCrVq1KG1+mTBkCAwPTjYmPj2fLli23XaeI5BxlmjdnW5EiABwbOtRwGpGcIzUpibIrVlARaNOsGTabzWgep39FNWjQIGbNmsW8efPYv38/vXv3JiEhgW7dugHQuXNnIiIi0sYPGDCAlStX8v7773PgwAHeeOMNtm3bRt++fQGw2WwMHDiQt99+m2XLlrF79246d+5MUFAQbdu2dfbmiEg2YL/59VTtnTu5cuqU2TAiOcS2UaMolZLCZZuNEFd4bIrzL+qyrEmTJlklS5a0vL29rfr161ubN29Oe61Zs2ZWly5d0o1fsmSJVaFCBcvb29uqWrWq9d1336V73eFwWK+//roVEBBg+fj4WA899JB18ODBe87jzMvERcS81JQU67C3t2WBtfaJJ0zHEckRthYsaFlgralf32nvkZH9t82yct61lPHx8fj7+xMXF+e083FExKy17dvTbMkSjnp5UeraNeyenqYjibitw8uWUa5NG1KBmA0bKN6okVPeJyP77xxxFZWI5Dx1PvyQWKBMcjJRkyaZjiPi1v64earJtqAgp5WbjFLBERG3lK9YMb5p1YpqwFurVpmOI+K2Lh87Rr19+wDwHTbMcJr/p4IjIm6ryUcfsc9mY8WKFfz222+m44i4pY+XLKEVsKBwYWoYvvfNf1PBERG3dd999/Hoo48CMOODDwynEXE/KSkpTJ4yhbVA4nvvYbO7Tq1wnSQiIk7wUo8ezAdenT6duBMnTMcRcSvffvstJ06coFChQjz99NOm46SjgiMibu3+Vq1o4ONDQWDXgAGm44i4lQK9evE+MPiZZ8iVK5fpOOmo4IiIW7PZ7Zxu1w6A0suX40hONpxIxD0cXLqU+8+fZwDQ9ZlnTMf5ExUcEXF7dT/4gMs2GyVTUogeNcp0HBG3cOaVVwDYVrw4xRo0MJzmz1RwRMTt5SlalF116wLgMWWK4TQi2d+lI0eod+AAALlfftlwmltTwRGRHOG+CRNIBepcusSRb781HUckW9vZvz95gN9y5aLaiy+ajnNLKjgikiMEN25MVLFiAJz6rwf8ikjGpCQmUu6HHwA436GDS10a/t9cM5WIiBN4v/IKw4GOv/9ObGys6Tgi2VLUiBGUTE3lks1GyPvvm45zWyo4IpJj1OnTh++rVeOP69f55JNPTMcRyZY++OUXxgPRzZrhW6CA6Ti3pYIjIjmGzWajf//+AEyePJnUlBTDiUSylx07dvDl1q1EeHpS5bPPTMe5IxUcEclROnbsyNN58/Lp0aNEjxhhOo5ItjJp0iQAnnjiCYoXL244zZ2p4IhIjpI7d256VKtGI8Br+nTTcUSyjQu//cYj8+bxANDfhR6qeTsqOCKS41SYMIEUoPblyxxeutR0HJFsYdeAATzhcDA9Vy4auOCN/f6XCo6I5DjFw8LYevPw+n/uxioit5d8/ToVV60C4MIzz7jspeH/zfUTiog4Qa6bd18NOXCAy4cPG04j4tqiXn+dEqmpXLTZCBk/3nSce6KCIyI5Us0XX2R/rlzkBn7VU8ZF7ijXrFkA7GvUCJ/8+c2GuUcqOCKSI9nsdi48/TQA5X74gZQbNwwnEnFN+xYtok58PClAhQ8+MB3nnqngiEiOVe/991np7c1Lqal8u3y56TgiLun8zdspRJcsScDNh9ZmByo4IpJj+ebPz/ohQ/gCmKinjIv8yblz51j4++8cBPyy2Qn5KjgikqP17t0bDw8P1qxZw6+//mo6johLmTFjBjNTU+lavz6Ve/Y0HSdDVHBEJEcrUaIEXR59lJeBk507m44j4jISExOZOnUqAH379webzXCijFHBEZEcb8DDDzMGeGjXLi4ePGg6johL2PDqqzwSE0PZYsV48sknTcfJMBUcEcnxqvfowd7cufEF9tx8GKdITmY5HBSbOpXZwMc1auDt7W06Uoap4IhIjmez27n87LMAVFi9mpTr1w0nEjFr55QpVLl+nRtAzY8+Mh3nL1HBEREB6o0bx3mbjWKpqWx79VXTcUSMuv7uuwBsq1SJghUrGk7z16jgiIgAPn5+7GncGIDcs2cbTiNizvE1awg9fRqAoPfeM5zmr1PBERG5qfJHH5EM1IiP58CCBabjiBjx+6BBeADbCxWi7GOPmY7zlzm14Fy6dImOHTvi5+dH/vz56d69O1evXr3j+H79+lGxYkVy5cpFyZIl6d+/P3FxcenG2Wy2P02LFi1y5qaISA4QWLs2m8qWZT4w58svTccRyXJxf/xBnR07/v3DwIFGs/xdns5ceceOHTlz5gyrVq0iOTmZbt260bNnTxYuXHjL8adPn+b06dOMHz+eKlWqcPz4cV544QVOnz7Nl//zl82cOXNo2bJl2s/5s8nDv0TEteVauJAuDRrg9d13DDxzhmLFipmOJJJlvpg+nRJAeW9vakdEmI7z91hOsm/fPguwtm7dmjZvxYoVls1ms06dOnXP61myZInl7e1tJScnp80DrKVLl/7lbHFxcRZgxcXF/eV1iIj7atSokQVYr732mukoIlkmOTnZKlWqlAVYn0ycaDrOLWVk/+20r6giIyPJnz8/df/rwVzh4eHY7Xa2bNlyz+uJi4vDz88PT8/0B5v69OlD4cKFqV+/Pp988gmWZd12HYmJicTHx6ebRERuZ9CgQVQBSo4fz7WLF03HEckS//rXvzh+/DiFChWiw/PPm47ztzmt4MTExFC0aNF08zw9PSlYsCAxMTH3tI4LFy4watQoev7P8y/eeustlixZwqpVq2jXrh0vvvgikyZNuu16xowZg7+/f9oUHByc8Q0SkRyjTevWrPD0pMeNG2wbMMB0HJEs8fvw4QQBL7zwArly5TId52/LcMF5+eWXb3mS739PBw4c+NvB4uPjadWqFVWqVOGNN95I99rrr79Oo0aNqF27NsOHD2fYsGGMGzfutuuKiIggLi4ubTp58uTfzici7svDy4tjrVsDUPyLL3CkpBhOJOJcez/7jKFHjnAI6HvzppfZXYZPMh48eDBdu3a945iyZcsSGBjIuXPn0s1PSUnh0qVLBAYG3nH5K1eu0LJlS/Lly8fSpUvx8vK64/jQ0FBGjRpFYmIiPj4+f3rdx8fnlvNFRG6n9uTJxC1dyn1JSUSNGkX9N980HUnEaS6OGAHArtKlCatUyXCazJHhglOkSBGKFCly13FhYWHExsYSHR1NSEgIAD///DMOh4PQ0NDbLhcfH0+LFi3w8fFh2bJl+Pr63vW9du7cSYECBVRiRCTT5AsKYm29ejTbuhXPiRNBBUfc1JkdO2hw9CgABdzo97nTzsGpXLkyLVu2pEePHkRFRbFx40b69u1Lhw4dCAoKAuDUqVNUqlSJqKgo4N/lpnnz5iQkJDB79mzi4+OJiYkhJiaG1NRUAL799ls+/vhj9uzZw+HDh5k2bRqjR4+mX79+ztoUEcmhyk+cSApQJzaWA7rXlrip/f364Q3s8fOjUufOpuNkGqfeB2fBggX07duXhx56CLvdTrt27Zg4cWLa68nJyRw8eJBr164BsH379rQrrMqVK5duXUePHqV06dJ4eXkxZcoUXnrpJSzLoly5ckyYMIEePXo4c1NEJAcKatCATSVL0vDECS68+ip06GA6kkimunbpEjU2bQIg4X8u6MnubNadrq92U/Hx8fj7+6ddgi4icjv75s+nUJcuTLTbefHECYoXL246kkimWfvsszRbsIBTnp4EXr2Kh4uf6pGR/beeRSUicgdVOnfm6UaNGO1wMGXKFNNxRDKNw+Eg6ocfSAAOt2rl8uUmo1RwRETuov+QIQBMnz6dhIQEw2lEMsfy5csZduECVfPlo8706abjZDoVHBGRu2jdujXlypal8eXLrB00yHQckUwxfvx4ADq8+CL57nL7luxIBUdE5C48PDyYHhbGMqDKnDk4kpNNRxL5W3YtXkzy+vV4eXm57VXIKjgiIvcg9P33uWyzUTo5mW3/c3d1kezm6tChRAKLqlZ12xPnVXBERO5B3oAAdt28Sam3TjaWbOzEunU0uPnIouqvvmo4jfOo4IiI3KOKkyeTBNSKi2Pf/Pmm44j8JUf698cD2F6oEOWfeMJ0HKdRwRERuUfFQkKIKlMGgMs3n90jkp1cOnKEert2AWAbOtRwGudSwRERyYDCo0cDEHr8OCc3bDCcRiRjdvbuTV7gN19faqngiIjIf1Tq0IHtBQvyK7Bo8mTTcUTu2Y24OKqsXg3AhS5dsNnduwK499aJiDhB/OzZhAAjly3jwoULpuOI3JNvJ07kusNBjIcH9d5/33Qcp1PBERHJoGZt2lC7dm2uX7/O1KlTTccRuSuHw8GIhQspD3w/dCheefKYjuR0KjgiIhlks9kYPnw4+YCksWO5pqM44uK+//57Dhw4QB4/P56IiDAdJ0uo4IiI/AXt2rUj0tubtxMS2Nq3r+k4Ine07pVX8AJ69ep116dwuwsVHBGRv8DT05OLbdoAUPqrr0i5ccNwIpFb2/vpp4zdvZtDwICePU3HyTIqOCIif1HdqVO5aLNRKiWFqOHDTccRuaW4V14B4FSZMhQvV85wmqyjgiMi8hflLlyY3c2aAVBg1iwsh8NwIpH0jv74I6F//AFA4XHjDKfJWio4IiJ/Q42ZM0kAKl+/zo7x403HEUnnxM3HMmwtWpQK7dqZjpOlVHBERP6GguXLs61GDQCssWMNpxH5f2eio2lw8CAAvm+8YTaMASo4IiJ/031TpnAD+O3iRXZt3Wo6jggAB154AR/gVz8/qvfubTpOllPBERH5m0o0bsyAxx/nGeC9Dz4wHUeESxcvEr9jBwBJgwYZTmOGCo6ISCbo/frrACxZsoSjR48aTiM53eQpU2ibmspTFSoQcvP3Zk6jgiMikglq1apF8+bNKZuaypocdK8RcT0JCQlMnDgRgMfffNPtH6p5Ozlzq0VEnODtDh04ADz900+c3bXLdBzJoZa/+iqeFy9y33338cQTT5iOY4wKjohIJqnbpQt78+XDF9j//POm40gOlJSQQMPJkzkGfNC2LZ6enqYjGaOCIyKSSWx2O4lDhgBQd9s2Lh06ZDiR5DSbX3qJ4NRUrtjt/OPVV03HMUoFR0QkE4W89hoHcuUiL/Br9+6m40gO4khJodi8eQDsb94c3wIFDCcySwVHRCQT2ex2LvfpA0CtDRuIO3HCcCLJKbaMGEH5pCTigVozZpiOY5wKjohIJgsdM4Yj3t7ktyx29OhhOo7kAJbDgd9HHwGwIywMv5IlDScyTwVHRCST2T09OdOtG5eAVRs3cu3aNdORxM1tffttql67xjWg2uzZpuO4BBUcEREnaPDhhzQrVYrRCQnMmjXLdBxxY5Zlse6TT7gObA0JoVDlyqYjuQSnFpxLly7RsWNH/Pz8yJ8/P927d+fq1at3XOb+++/HZrOlm1544YV0Y06cOEGrVq3InTs3RYsWZejQoaSkpDhzU0REMsTT15d+r7wCwLhx40hMTDScSNzVTz/9xNDjx6ns40Pl+fNNx3EZTi04HTt2ZO/evaxatYrly5ezbt06et7DHT579OjBmTNn0qax//WE3tTUVFq1akVSUhKbNm1i3rx5zJ07lxEjRjhzU0REMqxLly4UDwqixqlTrMmhzwMS57Isi7feeguAf/buTdEqVQwnciGWk+zbt88CrK1bt6bNW7FihWWz2axTp07ddrlmzZpZAwYMuO3r33//vWW3262YmJi0edOmTbP8/PysxMTEe8oWFxdnAVZcXNw9jRcR+atWPPOMZYF1wtPTSr52zXQccTNRs2ZZ9cHy8fG5477VXWRk/+20IziRkZHkz5+funXrps0LDw/HbrezZcuWOy67YMECChcuTLVq1YiIiEh3gl5kZCTVq1cnICAgbV6LFi2Ij49n7969t1xfYmIi8fHx6SYRkazQ5MMPOWezEZySwpaBA03HETdjGzaMLcBn9eoRFBRkOo5LcVrBiYmJoWjRounmeXp6UrBgQWJiYm673DPPPMNnn33GL7/8QkREBJ9++inPPvtsuvX+d7kB0n6+3XrHjBmDv79/2hQcHPxXN0tEJEPyFCnC3hYtACg2Zw4pN24YTiTuYteMGdS9fJlkoOF775mO43IyXHBefvnlP50E/L/TgQMH/nKgnj170qJFC6pXr07Hjh2ZP38+S5cu5ciRI395nREREcTFxaVNJ0+e/MvrEhHJqLqzZ3PRZqNscjKbBwwwHUfcxI3XXgNgS8WKBDVsaDiN68nwU7gGDx5M165d7zimbNmyBAYGcu7cuXTzU1JSuHTpEoGBgff8fqGhoQAcPnyY++67j8DAQKKiotKNOXv2LMBt1+vj44OPj889v6eISGbKFxTEmhYtuH/lSkrMmUPKRx/h6etrOpZkY7vnzCH0wgVSgVLTppmO45IyXHCKFClCkSJF7jouLCyM2NhYoqOjCQkJAeDnn3/G4XCklZZ7sXPnTgCKFSuWtt533nmHc+fOpX0FtmrVKvz8/Kiis8dFxEXVnTOHC0FBlE5OZkPfvjT++GPTkSQbuxoRAcCW++6j4QMPGE7jmpx2Dk7lypVp2bIlPXr0ICoqio0bN9K3b186dOiQdiLUqVOnqFSpUtoRmSNHjjBq1Ciio6M5duwYy5Yto3PnzjRt2pQaNWoA0Lx5c6pUqUKnTp3YtWsXP/zwA6+99hp9+vTRURoRcVl5AwPZ+/DD7AY+/u47kpOTTUeSbGrv/PmEnT2LAyg+ZYrpOC7LqffBWbBgAZUqVeKhhx7ikUceoXHjxsycOTPt9eTkZA4ePJh2lZS3tzc//fQTzZs3p1KlSgwePJh27drx7bffpi3j4eHB8uXL8fDwICwsjGeffZbOnTun3QdARMRV1f3sM8ILF2ZeTAyffvqp6TiSTS2cOJHjQGTZspS6eQK7/JnNsizLdIisFh8fj7+/P3Fxcfj5+ZmOIyI5yPjx4xk6dChlypTh4MGDeHl5mY4k2ciGDRto0qQJuT082LtlC6VvngKSU2Rk/61nUYmIZKHevXtTqkgR/nn0KOtffNF0HMlmXn/9dQCe7d49x5WbjFLBERHJQnny5GF248a8D1ScM4ekuzyfT+Q/tk2eTKk1a8jl5cVrNy8Rl9tTwRERyWJhs2YRY7dTPDWVLf/zMGGRW7EcDjxeeYW5wNKaNXXD2nuggiMiksVyFyrE/jZtACi7aBGJenyM3MXWd9+l9pUr3ABqTZ9uOk62oIIjImJAg9mzOXPzKE7kXW6eKjmb5XDgO3o0AFvr1CFA597cExUcEREDchUowOFnngGg6jffcOX0acOJxFVtHjmSGgkJXAMqz5tnOk62oYIjImJI2MyZHPPyoohlEf1fDxUW+Q9HSgr+48cDsK1BAwpXq2Y4UfahgiMiYohnrlycefFFvgaGbtnChQsXTEcSF7PppZeocuMG8UAN3RwyQ1RwREQMCp0wgbdr12bbtWuMGTPGdBxxIYmJiYz96ivWATseeoj85cqZjpStqOCIiBhkt9vTis2UKVM4eeKE4UTiKmbMmMG3Z87QITCQul99ZTpOtqOCIyJiWPPmzWnXoAGTEhP5vXlz03HEBcTHxzNq1CgA3njzTfL4+xtOlP2o4IiIGGaz2Rj53HP0ABofPMjv331nOpIYFvn44wy5cIG6993Hc889ZzpOtqSCIyLiAqr36MHmwEA8gHM9e5qOIwad3bOHhqtXMxyY3KYNnp6epiNlSyo4IiIuotC0aTiABqdPs3vWLNNxxJB9zzxDPmB/njzUHzvWdJxsSwVHRMRFlG/blk3ly//7h0GDsBwOs4Eky/2+ejWNdu8GIOmtt7B5eBhOlH2p4IiIuJByixaRAFS/epXIwYNNx5EsdqpbN7yB7YULU3PQINNxsjUVHBERFxJYpw5b778fgLxTp5J444bZQJJlfp01iyYnT+IA8k2ebDpOtqeCIyLiYuotXsyEvHlpmpTEJO3ocgSHw8H1IUMAiCxfnvLt2xtOlP2p4IiIuJg8RYtSYOJE4oC3335bj3DIARYsWMA/4+OZ4+VFhS++MB3HLajgiIi4oM6dO1OzZk3i4uL4uH9/03HEiRISEoiIiOAMcPattyhSs6bpSG5BBUdExAV5eHgwYdQo1gCDP/+coytXmo4kTjL99dc5deoUpUuXZuDAgabjuA0VHBERF/Vg69b4Fi2KF3Cua1fTccQJTkdH0/ODD/ga+ODNN/H19TUdyW2o4IiIuLDCn3xCMhB69ixbbz6bSNzHofbtyQdUyJePNs8+azqOW1HBERFxYfe1asWmkBAACo8aRWJ8vOFEkll2z5tHkyNHAPD46CNsdu2SM5M+TRERF1f7m284Z7dTJjmZTbp82C2kJidj9emDHYgsU4ZK3bqZjuR2VHBERFycX4kSHHr+eQDqrVzJma1bDSeSv2t99+7USEjgCnDfV1+ZjuOWVHBERLKBhlOn8mu+fBwDPhoxwnQc+RsuHj5Mtc8+A2BnmzYUrV3bcCL3pIIjIpIN2Dw8sH35JXWA91auZN26daYjyV80dehQEiyLIz4+hH3+uek4bksFR0Qkm6jevDndX3gBgL59+5KSkmI4kWTU5s2bGfHNN1QGYufOxTNXLtOR3JYKjohINvL2228TWKAAj+zezRqdcJytpKam8uKLLwLQvmtXQjp0MJzIvangiIhkI4UKFeLzJ57gXaDB119zcsMG05HkHv38/PPU27GDgv7+vPfee6bjuD2nFpxLly7RsWNH/Pz8yJ8/P927d+fq1au3HX/s2DFsNtstpy/+6+Fjt3p90aJFztwUERGX0WzaNHb5+5MXOPP441gOh+lIchdnduyg3ty5zAAWt25N0aJFTUdye04tOB07dmTv3r2sWrWK5cuXs27dOnr27Hnb8cHBwZw5cybd9Oabb5I3b14efvjhdGPnzJmTblzbtm2duSkiIi7D5uGB38KFJAH1z58ncvBg05HkDizL4sijj5If2J8nDw98/LHpSDmC0wrO/v37WblyJR9//DGhoaE0btyYSZMmsWjRIk6fPn3LZTw8PAgMDEw3LV26lKeeeoq8efOmG5s/f/504/T8DhHJSco88gibmjUD4L6JE4k7ftxwIrmdyFdeofHp06QAnp98goePj+lIOYLTCk5kZCT58+enbt26afPCw8Ox2+1s2bLlntYRHR3Nzp076d69+59e69OnD4ULF6Z+/fp88sknWJZ12/UkJiYSHx+fbhIRye7Cli3jd29vAhwOdv3PUW5xDZePH6fU2LEARIaFUf6ppwwnyjmcVnBiYmL+9B2jp6cnBQsWJCYm5p7WMXv2bCpXrkzDhg3TzX/rrbdYsmQJq1atol27drz44otMmjTptusZM2YM/v7+aVNwcHDGN0hExMX4+PlxZdw4AOru38/mpUsNJ5L/teORRyjucHDCy4t6y5ebjpOjZLjgvPzyy7c9Efg/04EDB/52sOvXr7Nw4cJbHr15/fXXadSoEbVr12b48OEMGzaMcTf/kN9KREQEcXFxadPJkyf/dj4REVdQs39/FjVoQC2g07BhJCQkmI4kN21asoTG+/YBEPfee/gWLGg4Uc7imdEFBg8eTNeuXe84pmzZsgQGBnLu3Ll081NSUrh06RKBgYF3fZ8vv/ySa9eu0blz57uODQ0NZdSoUSQmJuJzi+82fXx8bjlfRMQdPLxyJUOrVeOPw4d55ZVX+Oijj0xHyvGuXr1K51dewR8YUa8ebV56yXSkHCfDBadIkSIUKVLkruPCwsKIjY0lOjqakJAQAH7++WccDgehoaF3XX727Nk89thj9/ReO3fupECBAioxIpIj+fv7M3v2bFq0aMG2iRPZUbEitW/eUE7MGDZsGEeOHCE4OJj7V60yHSdHcto5OJUrV6Zly5b06NGDqKgoNm7cSN++fenQoQNBQUEAnDp1ikqVKhEVFZVu2cOHD7Nu3Tqev/n03P/27bff8vHHH7Nnzx4OHz7MtGnTGD16NP369XPWpoiIuLzmzZszPTyc9UDBAQO4eo/nOkrm2/LRR2yYNg349y1N/P39DSfKmZx6H5wFCxZQqVIlHnroIR555BEaN27MzJkz015PTk7m4MGDXLt2Ld1yn3zyCSVKlKB58+Z/WqeXlxdTpkwhLCyMWrVqMWPGDCZMmMDIkSOduSkiIi7vmblzOePhQamUFKL/8Q/TcXKkyydOEDR4MNuAKa1b89BDD5mOlGPZrDtdX+2m4uPj8ff3Jy4uDj8/P9NxREQyzfaxY6kzfDgA0e+9R8iwYYYT5Sy/lC/PA4cPc9LTk4InT5LnHs45lXuXkf23nkUlIuJG6gwbxrqqVQEoFhHBhYMHDSfKOTa9+ioPHD4MQPxHH6ncGKaCIyLiZur+8gu/e3sT5HBwuFkzPasqC5zato0KY8YAsKFuXarqJG/jVHBERNxM7iJFSJk/n0SgwdmzfNu3r+lIbi0lKYkz//gHhS2L33Llov7q1aYjCSo4IiJuqUL79mx64gm6A0/Nns3u3btNR3Jb33ToQN3YWBIAn2++wVvndroEFRwRETd1/5IlxDzyCIlJSTz99NN/umJV/r41a9bQ4ZtvGA782qsXpW5x9a+YoYIjIuKmbDYbc+bMISAggNN79/LVgw/e8cHEkjEXLlygY8eOpFoW57t1I2z6dNOR5L+o4IiIuLGiRYuyeO5cooBOW7awtksX05HcQmpyMl81bEjs6dNUrFjxjg98FjNUcERE3Fyzli05ffOrkwaffsre+fMNJ8r+frn/fnodOsQvdjtfLF5Mnjx5TEeS/6GCIyKSAzT5/nuiAgPxBfyee46Lv/1mOlK2tTEigvBNmwCwXniB6jVrGk4kt6KCIyKSA9g8PKi4eTPHvbwITk3l94YNSUlMNB0r2zm0YgVV330XgI01axI6ZYrhRHI7KjgiIjmEf6lSJH/+OdeAehcvsj401HSkbOXysWPQti35gT1+foTePIojrkkFR0QkBynXrh17Bg8GIHjXLmaOHWs4UfaQlJDA4Tp1KJ+URIyHB4Hr1+OZO7fpWHIHKjgiIjlM/fHj+bZ9exoAvSMiWLlypelILs2yLF7t1Ingy5dJAK4sWEDhGjVMx5K7UMEREcmBHv38c1p37YrD4aB9+/bs3bHDdCSXNXr0aMYvXUqY3c6+0aMp37696UhyD1RwRERyIJvNxowZM2jatClPxceTu149TkZGmo7lcpZMn85rr70GwLDJk6kXEWE4kdwrFRwRkRzK29ubpQsWEOHtTZnUVBLvv5/z+/ebjuUyIt94g5a9e/Mo8NJLL9G7d2/TkSQDVHBERHKwgiVKkHv9ek57eFAuKYmzdesSf+qU6VjGbZ80iZpvvokf8HLZsowfP950JMkgFRwRkRwusH59kr79los2G9WuXeO3atVIuHDBdCxj9ixYQJn+/ckNRBctSuju3djt2l1mN/oVExERSj/8MOfnzeMKUDc2lv3ly3P13DnTsbLc7nnzCOrUiQL8+143Vffv1+Xg2ZQKjoiIAFCpUydOTJuWVnImNW7MlStXTMfKMrs+/pgSXbtS0LLYmy8fpfbswbdgQdOx5C9SwRERkTRVX3iBk7NmMdrHh1cOHaJly5bExsaajuV069atY1Pv3mlHbkodOEC+4GDTseRvUMEREZF0qjz/PC02bqRAgQJs2rSJlmFhnI6ONh3Lab7++muaN29O35QUPi5XjrK//UbeoCDTseRvUsEREZE/CQkJYc2aNZQqVox3DhwgNTSUQ8uWmY6V6b7t1YsO7dqRmJhIq9at6fjrr+QOCDAdSzKBCo6IiNxSjRo12PjNN9zn7U1waiqF27Zl2/vvm46VKVISE/kpNJTWM2cyE3ihVy++/vprcuXKZTqaZBIVHBERua3i9evjv3s3e/Plo4BlUXPIEH5q0wbL4TAd7S+7ePgw24sXJzwqCoDyDz7I1KlT8fT0NJxMMpMKjoiI3FGBChW479gxNpctixcQvmwZG8qU4crZs6ajZdi+xYu5Urky9S9e5DqwuW9fGq1ejU33uXE7+hUVEZG78i1YkNBDh9j45JOkAE1OnGDdffcRmU2eX5WanMzqNm0o26EDpVNS+MPTk1NLltBg0iTT0cRJVHBEROSe2Ox2Gi1ZwsEpUzjh4cHwhAQaN27MiBEjSE5ONh3vto4fP87jzZpRc9kyfIFtAQHkO3CAck8+aTqaOJEKjoiIZEjVF1/E/+xZ6nTqhMPhYNSoUYwvWZKd06ebjpZO8o0bjB83jqpVq7IsMpI+Pj5sfOYZQk6fxv+++0zHEydTwRERkQzzL1SI+fPns2jRIprmz8/QmBhq9e7NmvLlOb1zp+l4RL//PocKFGDbsGEkJCTQqFEj3tmzh0YLFuh8mxzCZlmWZTpEVouPj8ff35+4uDj8/PxMxxERydYuHzzI/sceo+FvvwGQAGyuW5can35KkUqVsjTLr3PmkDhkCPUuXQLgoIcHG6dPp+tzz+mBmW4gI/tvp/1qv/POOzRs2JDcuXOTP3/+e1rGsixGjBhBsWLFyJUrF+Hh4Rw6dCjdmEuXLtGxY0f8/PzInz8/3bt35+rVq07YAhERuRcFKlak4cGD7J0xg/358pEHeGjbNnwrV2Z19eoc2LTJqe+fmpxM5Kuvsr1AAWo89xz1Ll0iGVhXvTpF9uzhueefV7nJgZz2K56UlMSTTz5J796973mZsWPHMnHiRKZPn86WLVvIkycPLVq04MaNG2ljOnbsyN69e1m1ahXLly9n3bp19OzZ0xmbICIiGVC1Z08qxcay4803OZg7N/mA2nv2UKdRI5o2bcq0adM4d+pUpryXZVns2rWLiIgI5hQqRNjo0dSJjSUViLzvPs6tW0fTX3+lYBYfQRIXYjnZnDlzLH9//7uOczgcVmBgoDVu3Li0ebGxsZaPj4/1+eefW5ZlWfv27bMAa+vWrWljVqxYYdlsNuvUqVP3nCkuLs4CrLi4uHvfEBERuWeOlBTr13HjrEkhIZbdbrcAC7AOgbXNz8/6qUkTa+vYsdbZAwcsh8Nx1/WlJCVZR3780VrXv7/1c+XK1uPFiqWt8x9gxdps1toGDazTkZFZsHViSkb23y5z28ajR48SExNDeHh42jx/f39CQ0OJjIykQ4cOREZGkj9/furWrZs2Jjw8HLvdzpYtW/jnP/95y3UnJiaSmJiY9nN8fLzzNkRERLB5eFB9yBCqDxlCm5MnWbx4MTvmzKHcvn0QHw/r1/97GjaMszYbZ/LkYWOpUkSFhODp6Ynf9ev8c/NmfOPj8UtIoMSNG5QFyt5c/2bgOx8fWrVqxdNPPYX3Qw/RtHBhg1ssrsZlCk5MTAwAAf/zkLOAgIC012JiYihatGi61z09PSlYsGDamFsZM2YMb775ZiYnFhGRexEcHMyQIUNgyBBOrVnD8U8+wbZ+PaX++IOglBQCLIuAq1f5fu9e5u/dC/y7yHzwP+u5ARzNnZsLFStyf4cO9HvxRfLmzZvVmyPZRIYKzssvv8x77713xzH79++nkot95xkREcGgQYPSfo6Pjyc4ONhgIhGRnKn4/fdT/P77036+dvYsJ378kSu//kql3Ll5N3duHA4HvjdusD46Go+gIHxLlaJwSAglHnyQyt7e5sJLtpKhgjN48GC6du16xzFly5a94+u3ExgYCMDZs2cpVqxY2vyzZ89Sq1attDHnzp1Lt1xKSgqXLl1KW/5WfHx88PHx+Uu5RETEeXIHBFCpUycA6hnOIu4lQwWnSJEiFClSxClBypQpQ2BgIKtXr04rNPHx8WzZsiXtSqywsDBiY2OJjo4mJCQEgJ9//hmHw0FoaKhTcomIiEj247TLxE+cOMHOnTs5ceIEqamp7Ny5k507d6a7Z02lSpVYunQpADabjYEDB/L222+zbNkydu/eTefOnQkKCqJt27YAVK5cmZYtW9KjRw+ioqLYuHEjffv2pUOHDgQFBTlrU0RERCSbcdpJxiNGjGDevHlpP9euXRuAX375hftvfv968OBB4uLi0sYMu3lL7Z49exIbG0vjxo1ZuXIlvr6+aWMWLFhA3759eeihh7Db7bRr146JEyc6azNEREQkG9KjGvSoBhERkWzBJR7VICIiImKKCo6IiIi4HRUcERERcTsqOCIiIuJ2VHBERETE7ajgiIiIiNtRwRERERG3o4IjIiIibkcFR0RERNyO0x7V4Mr+c/Pm+Ph4w0lERETkXv1nv30vD2HIkQXnypUrAAQHBxtOIiIiIhl15coV/P397zgmRz6LyuFwcPr0afLly4fNZsvUdcfHxxMcHMzJkyf1nKv/oc/mzvT53Jk+nzvT53N7+mzuLDt9PpZlceXKFYKCgrDb73yWTY48gmO32ylRooRT38PPz8/lf6OYos/mzvT53Jk+nzvT53N7+mzuLLt8Pnc7cvMfOslYRERE3I4KjoiIiLgdFZxM5uPjw8iRI/Hx8TEdxeXos7kzfT53ps/nzvT53J4+mztz188nR55kLCIiIu5NR3BERETE7ajgiIiIiNtRwRERERG3o4IjIiIibkcFJxNNmTKF0qVL4+vrS2hoKFFRUaYjuYx169bRunVrgoKCsNlsfPPNN6YjuYwxY8ZQr1498uXLR9GiRWnbti0HDx40HctlTJs2jRo1aqTdhCwsLIwVK1aYjuWS3n33XWw2GwMHDjQdxSW88cYb2Gy2dFOlSpVMx3Ipp06d4tlnn6VQoULkypWL6tWrs23bNtOxMoUKTiZZvHgxgwYNYuTIkWzfvp2aNWvSokULzp07ZzqaS0hISKBmzZpMmTLFdBSXs3btWvr06cPmzZtZtWoVycnJNG/enISEBNPRXEKJEiV49913iY6OZtu2bTz44IO0adOGvXv3mo7mUrZu3cqMGTOoUaOG6SgupWrVqpw5cyZt2rBhg+lILuPy5cs0atQILy8vVqxYwb59+3j//fcpUKCA6WiZw5JMUb9+fatPnz5pP6emplpBQUHWmDFjDKZyTYC1dOlS0zFc1rlz5yzAWrt2rekoLqtAgQLWxx9/bDqGy7hy5YpVvnx5a9WqVVazZs2sAQMGmI7kEkaOHGnVrFnTdAyXNXz4cKtx48amYziNjuBkgqSkJKKjowkPD0+bZ7fbCQ8PJzIy0mAyyY7i4uIAKFiwoOEkric1NZVFixaRkJBAWFiY6Tguo0+fPrRq1Srd30Hyb4cOHSIoKIiyZcvSsWNHTpw4YTqSy1i2bBl169blySefpGjRotSuXZtZs2aZjpVpVHAywYULF0hNTSUgICDd/ICAAGJiYgylkuzI4XAwcOBAGjVqRLVq1UzHcRm7d+8mb968+Pj48MILL7B06VKqVKliOpZLWLRoEdu3b2fMmDGmo7ic0NBQ5s6dy8qVK5k2bRpHjx6lSZMmXLlyxXQ0l/D7778zbdo0ypcvzw8//EDv3r3p378/8+bNMx0tU+TIp4mLuKo+ffqwZ88enSfwPypWrMjOnTuJi4vjyy+/pEuXLqxduzbHl5yTJ08yYMAAVq1aha+vr+k4Lufhhx9O+/8aNWoQGhpKqVKlWLJkCd27dzeYzDU4HA7q1q3L6NGjAahduzZ79uxh+vTpdOnSxXC6v09HcDJB4cKF8fDw4OzZs+nmnz17lsDAQEOpJLvp27cvy5cv55dffqFEiRKm47gUb29vypUrR0hICGPGjKFmzZp89NFHpmMZFx0dzblz56hTpw6enp54enqydu1aJk6ciKenJ6mpqaYjupT8+fNToUIFDh8+bDqKSyhWrNif/pFQuXJlt/kaTwUnE3h7exMSEsLq1avT5jkcDlavXq3zBOSuLMuib9++LF26lJ9//pkyZcqYjuTyHA4HiYmJpmMY99BDD7F792527tyZNtWtW5eOHTuyc+dOPDw8TEd0KVevXuXIkSMUK1bMdBSX0KhRoz/dkuK3336jVKlShhJlLn1FlUkGDRpEly5dqFu3LvXr1+fDDz8kISGBbt26mY7mEq5evZruX01Hjx5l586dFCxYkJIlSxpMZl6fPn1YuHAh//rXv8iXL1/aeVv+/v7kypXLcDrzIiIiePjhhylZsiRXrlxh4cKFrFmzhh9++MF0NOPy5cv3p3O18uTJQ6FChXQOFzBkyBBat25NqVKlOH36NCNHjsTDw4Onn37adDSX8NJLL9GwYUNGjx7NU089RVRUFDNnzmTmzJmmo2UO05dxuZNJkyZZJUuWtLy9va369etbmzdvNh3JZfzyyy8W8KepS5cupqMZd6vPBbDmzJljOppLeO6556xSpUpZ3t7eVpEiRayHHnrI+vHHH03Hclm6TPz/tW/f3ipWrJjl7e1tFS9e3Grfvr11+PBh07FcyrfffmtVq1bN8vHxsSpVqmTNnDnTdKRMY7MsyzLUrUREREScQufgiIiIiNtRwRERERG3o4IjIiIibkcFR0RERNyOCo6IiIi4HRUcERERcTsqOCIiIuJ2VHBERETE7ajgiIiIiNtRwRERERG3o4IjIiIibkcFR0RERNzO/wGFZ1f6AgzeNAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.2. Ajuste de la curva $y = exp(x)$ en el intervalo $[0,1]$."
      ],
      "metadata": {
        "id": "Gi5GYZwwb3pk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sciann import Variable, Functional, SciModel\n",
        "from sciann.constraints import Data\n",
        "from tensorflow import keras\n",
        "import sciann as sn\n",
        "import time\n",
        "\n",
        "\n",
        "# Generación de datos sintéticos.\n",
        "x_true = np.linspace(0, 1, 10000)\n",
        "y_true = np.exp(x_true)\n",
        "dy_true = np.exp(x_true)\n",
        "\n",
        "# Definimos la estructura de la función que queremos aprender.\n",
        "x = Variable('x')\n",
        "xf = Functional('xf', x)\n",
        "\n",
        "\n",
        "y = Functional('y', x, [10, 10, 10], activation=['relu', 'relu', 'relu'])\n",
        "\n",
        "\n",
        "# Imponemos restricciones al modelo.\n",
        "\n",
        "dy_dx = sn.diff(y, x)\n",
        "c1 = Data(y)\n",
        "\n",
        "# Definimos el modelo.\n",
        "model = SciModel(x, [y, dy_dx], optimizer='adam')\n",
        "model.summary()\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Entrenamiento.\n",
        "model.train(x_true,\n",
        "            [y_true, dy_true],\n",
        "            epochs=1000,\n",
        "            learning_rate={\"scheduler\": \"ExponentialDecay\",\n",
        "                           \"initial_learning_rate\": 1e-3,\n",
        "                           \"final_learning_rate\": 1e-5,\n",
        "                           \"decay_epochs\": 10,\n",
        "                           \"verify\": False},\n",
        "            batch_size=32,\n",
        "            callbacks=[keras.callbacks.EarlyStopping(monitor=\"y_loss\", min_delta = 0, patience=5,verbose=1)]\n",
        "            )\n",
        "\n",
        "print(f\"Training finished in {time.time()-start_time}s. \")\n",
        "\n",
        "# Predicción.\n",
        "y_pred = y.eval(model, x_true)\n",
        "\n",
        "# Mostramos los resultados.\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(x_true, y_true, '-k', x_true, y_pred, '--r')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IDAbSgvLRFot",
        "outputId": "ca9fdfca-cf26-4a36-e225-b15754c812eb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Call `model.compile()` after using set_trainable.\n",
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " x (InputLayer)              [(None, 1)]               0         \n",
            "                                                                 \n",
            " D10b_16 (Dense)             (None, 10)                20        \n",
            "                                                                 \n",
            " sci_rowdy_activation_layer_  (None, 10)               3         \n",
            " 15 (SciRowdyActivationLayer                                     \n",
            " )                                                               \n",
            "                                                                 \n",
            " D10b_17 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            " sci_rowdy_activation_layer_  (None, 10)               3         \n",
            " 16 (SciRowdyActivationLayer                                     \n",
            " )                                                               \n",
            "                                                                 \n",
            " D10b_18 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            " sci_rowdy_activation_layer_  (None, 10)               3         \n",
            " 17 (SciRowdyActivationLayer                                     \n",
            " )                                                               \n",
            "                                                                 \n",
            " y (Field)                   (None, 1)                 11        \n",
            "                                                                 \n",
            " Grad__6 (Lambda)            (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 260\n",
            "Trainable params: 260\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Total samples: 10000 \n",
            "Batch size: 32 \n",
            "Total batches: 313 \n",
            "\n",
            "Epoch 1/1000\n",
            "313/313 [==============================] - 4s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 1.0849 - y_loss: 0.4956 - Grad__6_loss: 0.5894 - lr: 0.0010 - time: 3.6613\n",
            "Epoch 2/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0656 - y_loss: 5.9493e-04 - Grad__6_loss: 0.0650 - lr: 6.3096e-04 - time: 1.4544\n",
            "Epoch 3/1000\n",
            "313/313 [==============================] - 2s 7ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0428 - y_loss: 4.0898e-04 - Grad__6_loss: 0.0424 - lr: 3.9811e-04 - time: 2.1073\n",
            "Epoch 4/1000\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0325 - y_loss: 2.5278e-04 - Grad__6_loss: 0.0322 - lr: 2.5119e-04 - time: 1.9720\n",
            "Epoch 5/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0262 - y_loss: 1.8146e-04 - Grad__6_loss: 0.0260 - lr: 1.5849e-04 - time: 1.3931\n",
            "Epoch 6/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0230 - y_loss: 1.4717e-04 - Grad__6_loss: 0.0228 - lr: 1.0000e-04 - time: 1.4516\n",
            "Epoch 7/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0207 - y_loss: 1.2743e-04 - Grad__6_loss: 0.0205 - lr: 6.3096e-05 - time: 1.3547\n",
            "Epoch 8/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0195 - y_loss: 1.1064e-04 - Grad__6_loss: 0.0194 - lr: 3.9811e-05 - time: 1.3151\n",
            "Epoch 9/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0187 - y_loss: 9.9147e-05 - Grad__6_loss: 0.0186 - lr: 2.5119e-05 - time: 1.3701\n",
            "Epoch 10/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0182 - y_loss: 9.7911e-05 - Grad__6_loss: 0.0181 - lr: 1.5849e-05 - time: 1.3636\n",
            "Epoch 11/1000\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0178 - y_loss: 8.5522e-05 - Grad__6_loss: 0.0177 - lr: 1.0000e-05 - time: 1.5278\n",
            "Epoch 12/1000\n",
            "313/313 [==============================] - 2s 7ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0175 - y_loss: 8.5720e-05 - Grad__6_loss: 0.0174 - lr: 1.0000e-05 - time: 2.2011\n",
            "Epoch 13/1000\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0171 - y_loss: 7.8512e-05 - Grad__6_loss: 0.0170 - lr: 1.0000e-05 - time: 2.0420\n",
            "Epoch 14/1000\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0167 - y_loss: 7.7075e-05 - Grad__6_loss: 0.0167 - lr: 1.0000e-05 - time: 1.5533\n",
            "Epoch 15/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0163 - y_loss: 7.2770e-05 - Grad__6_loss: 0.0162 - lr: 1.0000e-05 - time: 1.3898\n",
            "Epoch 16/1000\n",
            "313/313 [==============================] - 1s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0159 - y_loss: 6.6698e-05 - Grad__6_loss: 0.0158 - lr: 1.0000e-05 - time: 1.4727\n",
            "Epoch 17/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0155 - y_loss: 6.2863e-05 - Grad__6_loss: 0.0154 - lr: 1.0000e-05 - time: 1.4318\n",
            "Epoch 18/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0149 - y_loss: 5.7409e-05 - Grad__6_loss: 0.0149 - lr: 1.0000e-05 - time: 1.3214\n",
            "Epoch 19/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0145 - y_loss: 5.6143e-05 - Grad__6_loss: 0.0145 - lr: 1.0000e-05 - time: 1.4409\n",
            "Epoch 20/1000\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0141 - y_loss: 4.8760e-05 - Grad__6_loss: 0.0140 - lr: 1.0000e-05 - time: 1.5546\n",
            "Epoch 21/1000\n",
            "313/313 [==============================] - 2s 7ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0135 - y_loss: 4.6051e-05 - Grad__6_loss: 0.0135 - lr: 1.0000e-05 - time: 2.1328\n",
            "Epoch 22/1000\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0131 - y_loss: 3.9487e-05 - Grad__6_loss: 0.0131 - lr: 1.0000e-05 - time: 1.6155\n",
            "Epoch 23/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0126 - y_loss: 3.7537e-05 - Grad__6_loss: 0.0126 - lr: 1.0000e-05 - time: 1.4195\n",
            "Epoch 24/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0121 - y_loss: 3.3240e-05 - Grad__6_loss: 0.0121 - lr: 1.0000e-05 - time: 1.4573\n",
            "Epoch 25/1000\n",
            "313/313 [==============================] - 1s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0116 - y_loss: 3.1197e-05 - Grad__6_loss: 0.0116 - lr: 1.0000e-05 - time: 1.4712\n",
            "Epoch 26/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0111 - y_loss: 2.9416e-05 - Grad__6_loss: 0.0111 - lr: 1.0000e-05 - time: 1.3639\n",
            "Epoch 27/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0107 - y_loss: 2.5647e-05 - Grad__6_loss: 0.0106 - lr: 1.0000e-05 - time: 1.3107\n",
            "Epoch 28/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0102 - y_loss: 2.1964e-05 - Grad__6_loss: 0.0102 - lr: 1.0000e-05 - time: 1.4412\n",
            "Epoch 29/1000\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0098 - y_loss: 2.1444e-05 - Grad__6_loss: 0.0098 - lr: 1.0000e-05 - time: 1.9396\n",
            "Epoch 30/1000\n",
            "313/313 [==============================] - 2s 7ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0093 - y_loss: 1.7403e-05 - Grad__6_loss: 0.0093 - lr: 1.0000e-05 - time: 2.2722\n",
            "Epoch 31/1000\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0089 - y_loss: 1.6875e-05 - Grad__6_loss: 0.0089 - lr: 1.0000e-05 - time: 1.5782\n",
            "Epoch 32/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0086 - y_loss: 1.6425e-05 - Grad__6_loss: 0.0086 - lr: 1.0000e-05 - time: 1.4299\n",
            "Epoch 33/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0084 - y_loss: 1.4274e-05 - Grad__6_loss: 0.0084 - lr: 1.0000e-05 - time: 1.3065\n",
            "Epoch 34/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0084 - y_loss: 1.3089e-05 - Grad__6_loss: 0.0084 - lr: 1.0000e-05 - time: 1.3223\n",
            "Epoch 35/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0081 - y_loss: 1.1167e-05 - Grad__6_loss: 0.0081 - lr: 1.0000e-05 - time: 1.4357\n",
            "Epoch 36/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0080 - y_loss: 9.7134e-06 - Grad__6_loss: 0.0080 - lr: 1.0000e-05 - time: 1.4517\n",
            "Epoch 37/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0079 - y_loss: 9.4303e-06 - Grad__6_loss: 0.0079 - lr: 1.0000e-05 - time: 1.3823\n",
            "Epoch 38/1000\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0078 - y_loss: 9.3042e-06 - Grad__6_loss: 0.0078 - lr: 1.0000e-05 - time: 2.0703\n",
            "Epoch 39/1000\n",
            "313/313 [==============================] - 4s 12ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0076 - y_loss: 7.3075e-06 - Grad__6_loss: 0.0076 - lr: 1.0000e-05 - time: 3.8999\n",
            "Epoch 40/1000\n",
            "313/313 [==============================] - 2s 7ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0075 - y_loss: 7.0890e-06 - Grad__6_loss: 0.0075 - lr: 1.0000e-05 - time: 2.1248\n",
            "Epoch 41/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0075 - y_loss: 6.4724e-06 - Grad__6_loss: 0.0075 - lr: 1.0000e-05 - time: 1.4048\n",
            "Epoch 42/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0077 - y_loss: 7.0876e-06 - Grad__6_loss: 0.0077 - lr: 1.0000e-05 - time: 1.4296\n",
            "Epoch 43/1000\n",
            "313/313 [==============================] - 1s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0077 - y_loss: 5.8911e-06 - Grad__6_loss: 0.0077 - lr: 1.0000e-05 - time: 1.4825\n",
            "Epoch 44/1000\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0077 - y_loss: 5.9572e-06 - Grad__6_loss: 0.0077 - lr: 1.0000e-05 - time: 1.5358\n",
            "Epoch 45/1000\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0078 - y_loss: 5.6352e-06 - Grad__6_loss: 0.0078 - lr: 1.0000e-05 - time: 1.7810\n",
            "Epoch 46/1000\n",
            "313/313 [==============================] - 2s 7ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0079 - y_loss: 5.4693e-06 - Grad__6_loss: 0.0079 - lr: 1.0000e-05 - time: 2.3112\n",
            "Epoch 47/1000\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0078 - y_loss: 4.9996e-06 - Grad__6_loss: 0.0078 - lr: 1.0000e-05 - time: 1.5347\n",
            "Epoch 48/1000\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0078 - y_loss: 5.2157e-06 - Grad__6_loss: 0.0078 - lr: 1.0000e-05 - time: 1.5634\n",
            "Epoch 49/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0078 - y_loss: 4.5374e-06 - Grad__6_loss: 0.0077 - lr: 1.0000e-05 - time: 1.4003\n",
            "Epoch 50/1000\n",
            "313/313 [==============================] - 1s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0077 - y_loss: 4.8198e-06 - Grad__6_loss: 0.0077 - lr: 1.0000e-05 - time: 1.4912\n",
            "Epoch 51/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0075 - y_loss: 4.5810e-06 - Grad__6_loss: 0.0075 - lr: 1.0000e-05 - time: 1.3664\n",
            "Epoch 52/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0073 - y_loss: 4.5314e-06 - Grad__6_loss: 0.0073 - lr: 1.0000e-05 - time: 1.3431\n",
            "Epoch 53/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0073 - y_loss: 4.1101e-06 - Grad__6_loss: 0.0072 - lr: 1.0000e-05 - time: 1.3333\n",
            "Epoch 54/1000\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0071 - y_loss: 4.3056e-06 - Grad__6_loss: 0.0071 - lr: 1.0000e-05 - time: 1.9644\n",
            "Epoch 55/1000\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0072 - y_loss: 4.2796e-06 - Grad__6_loss: 0.0072 - lr: 1.0000e-05 - time: 2.0549\n",
            "Epoch 56/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0072 - y_loss: 4.0552e-06 - Grad__6_loss: 0.0072 - lr: 1.0000e-05 - time: 1.3714\n",
            "Epoch 57/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0072 - y_loss: 3.4651e-06 - Grad__6_loss: 0.0072 - lr: 1.0000e-05 - time: 1.3194\n",
            "Epoch 58/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0072 - y_loss: 3.7585e-06 - Grad__6_loss: 0.0072 - lr: 1.0000e-05 - time: 1.3362\n",
            "Epoch 59/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0073 - y_loss: 3.5332e-06 - Grad__6_loss: 0.0073 - lr: 1.0000e-05 - time: 1.3300\n",
            "Epoch 60/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0073 - y_loss: 3.8952e-06 - Grad__6_loss: 0.0073 - lr: 1.0000e-05 - time: 1.3977\n",
            "Epoch 61/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0072 - y_loss: 3.3046e-06 - Grad__6_loss: 0.0072 - lr: 1.0000e-05 - time: 1.3485\n",
            "Epoch 62/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0073 - y_loss: 3.4563e-06 - Grad__6_loss: 0.0073 - lr: 1.0000e-05 - time: 1.3814\n",
            "Epoch 63/1000\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0073 - y_loss: 3.1196e-06 - Grad__6_loss: 0.0073 - lr: 1.0000e-05 - time: 1.8763\n",
            "Epoch 64/1000\n",
            "313/313 [==============================] - 2s 7ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0072 - y_loss: 3.0748e-06 - Grad__6_loss: 0.0072 - lr: 1.0000e-05 - time: 2.2152\n",
            "Epoch 65/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0072 - y_loss: 2.7595e-06 - Grad__6_loss: 0.0072 - lr: 1.0000e-05 - time: 1.4308\n",
            "Epoch 66/1000\n",
            "313/313 [==============================] - 1s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0073 - y_loss: 2.7922e-06 - Grad__6_loss: 0.0073 - lr: 1.0000e-05 - time: 1.4649\n",
            "Epoch 67/1000\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0072 - y_loss: 2.8854e-06 - Grad__6_loss: 0.0072 - lr: 1.0000e-05 - time: 1.5098\n",
            "Epoch 68/1000\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0072 - y_loss: 2.7448e-06 - Grad__6_loss: 0.0072 - lr: 1.0000e-05 - time: 1.5092\n",
            "Epoch 69/1000\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0072 - y_loss: 2.9175e-06 - Grad__6_loss: 0.0072 - lr: 1.0000e-05 - time: 1.7050\n",
            "Epoch 70/1000\n",
            "313/313 [==============================] - 3s 10ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0072 - y_loss: 2.9638e-06 - Grad__6_loss: 0.0072 - lr: 1.0000e-05 - time: 3.0539\n",
            "Epoch 71/1000\n",
            "313/313 [==============================] - 2s 7ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0072 - y_loss: 3.3091e-06 - Grad__6_loss: 0.0072 - lr: 1.0000e-05 - time: 2.3071\n",
            "Epoch 72/1000\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0071 - y_loss: 2.7400e-06 - Grad__6_loss: 0.0071 - lr: 1.0000e-05 - time: 1.5977\n",
            "Epoch 73/1000\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0071 - y_loss: 2.7464e-06 - Grad__6_loss: 0.0071 - lr: 1.0000e-05 - time: 1.5283\n",
            "Epoch 74/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0071 - y_loss: 2.4892e-06 - Grad__6_loss: 0.0071 - lr: 1.0000e-05 - time: 1.4358\n",
            "Epoch 75/1000\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0070 - y_loss: 2.6965e-06 - Grad__6_loss: 0.0070 - lr: 1.0000e-05 - time: 1.6189\n",
            "Epoch 76/1000\n",
            "313/313 [==============================] - 1s 4ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0070 - y_loss: 2.6999e-06 - Grad__6_loss: 0.0070 - lr: 1.0000e-05 - time: 1.4473\n",
            "Epoch 77/1000\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0070 - y_loss: 2.4060e-06 - Grad__6_loss: 0.0070 - lr: 1.0000e-05 - time: 1.6314\n",
            "Epoch 78/1000\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0070 - y_loss: 2.3743e-06 - Grad__6_loss: 0.0070 - lr: 1.0000e-05 - time: 1.8956\n",
            "Epoch 79/1000\n",
            "313/313 [==============================] - 2s 7ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0069 - y_loss: 2.3246e-06 - Grad__6_loss: 0.0069 - lr: 1.0000e-05 - time: 2.2746\n",
            "Epoch 80/1000\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0068 - y_loss: 2.6167e-06 - Grad__6_loss: 0.0068 - lr: 1.0000e-05 - time: 1.8989\n",
            "Epoch 81/1000\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0068 - y_loss: 2.2746e-06 - Grad__6_loss: 0.0068 - lr: 1.0000e-05 - time: 1.6691\n",
            "Epoch 82/1000\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0068 - y_loss: 2.3230e-06 - Grad__6_loss: 0.0068 - lr: 1.0000e-05 - time: 1.8672\n",
            "Epoch 83/1000\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0067 - y_loss: 2.5930e-06 - Grad__6_loss: 0.0067 - lr: 1.0000e-05 - time: 2.0042\n",
            "Epoch 84/1000\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0066 - y_loss: 2.1733e-06 - Grad__6_loss: 0.0066 - lr: 1.0000e-05 - time: 1.6920\n",
            "Epoch 85/1000\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0066 - y_loss: 2.6218e-06 - Grad__6_loss: 0.0066 - lr: 1.0000e-05 - time: 1.9204\n",
            "Epoch 86/1000\n",
            "313/313 [==============================] - 3s 8ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0065 - y_loss: 2.4549e-06 - Grad__6_loss: 0.0065 - lr: 1.0000e-05 - time: 2.5687\n",
            "Epoch 87/1000\n",
            "313/313 [==============================] - 2s 7ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0065 - y_loss: 2.2803e-06 - Grad__6_loss: 0.0065 - lr: 1.0000e-05 - time: 2.1285\n",
            "Epoch 88/1000\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0064 - y_loss: 2.0989e-06 - Grad__6_loss: 0.0064 - lr: 1.0000e-05 - time: 1.6906\n",
            "Epoch 89/1000\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0064 - y_loss: 2.6318e-06 - Grad__6_loss: 0.0064 - lr: 1.0000e-05 - time: 1.9254\n",
            "Epoch 90/1000\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0063 - y_loss: 2.1427e-06 - Grad__6_loss: 0.0063 - lr: 1.0000e-05 - time: 1.7574\n",
            "Epoch 91/1000\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0062 - y_loss: 2.5407e-06 - Grad__6_loss: 0.0062 - lr: 1.0000e-05 - time: 1.8461\n",
            "Epoch 92/1000\n",
            "313/313 [==============================] - 2s 8ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0062 - y_loss: 1.9043e-06 - Grad__6_loss: 0.0062 - lr: 1.0000e-05 - time: 2.4651\n",
            "Epoch 93/1000\n",
            "313/313 [==============================] - 3s 9ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0062 - y_loss: 2.5491e-06 - Grad__6_loss: 0.0062 - lr: 1.0000e-05 - time: 2.8774\n",
            "Epoch 94/1000\n",
            "313/313 [==============================] - 2s 8ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0061 - y_loss: 2.1158e-06 - Grad__6_loss: 0.0061 - lr: 1.0000e-05 - time: 2.3753\n",
            "Epoch 95/1000\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0060 - y_loss: 2.3797e-06 - Grad__6_loss: 0.0060 - lr: 1.0000e-05 - time: 1.9260\n",
            "Epoch 96/1000\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0059 - y_loss: 2.0465e-06 - Grad__6_loss: 0.0059 - lr: 1.0000e-05 - time: 2.0105\n",
            "Epoch 97/1000\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0059 - y_loss: 1.8914e-06 - Grad__6_loss: 0.0059 - lr: 1.0000e-05 - time: 1.9916\n",
            "Epoch 98/1000\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0058 - y_loss: 1.9527e-06 - Grad__6_loss: 0.0058 - lr: 1.0000e-05 - time: 1.6226\n",
            "Epoch 99/1000\n",
            "313/313 [==============================] - 2s 7ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0058 - y_loss: 2.0090e-06 - Grad__6_loss: 0.0058 - lr: 1.0000e-05 - time: 2.1364\n",
            "Epoch 100/1000\n",
            "313/313 [==============================] - 2s 8ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0057 - y_loss: 2.0155e-06 - Grad__6_loss: 0.0057 - lr: 1.0000e-05 - time: 2.4887\n",
            "Epoch 101/1000\n",
            "313/313 [==============================] - 2s 5ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0056 - y_loss: 2.4901e-06 - Grad__6_loss: 0.0056 - lr: 1.0000e-05 - time: 1.6840\n",
            "Epoch 102/1000\n",
            "313/313 [==============================] - 2s 6ms/step - batch: 156.0000 - size: 31.9489 - loss: 0.0056 - y_loss: 2.3139e-06 - Grad__6_loss: 0.0056 - lr: 1.0000e-05 - time: 1.7983\n",
            "Epoch 102: early stopping\n",
            "Training finished in 181.3748004436493s. \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}